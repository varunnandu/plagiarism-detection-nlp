{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.cluster import KMeans\n",
    "from numbers import Number\n",
    "from pandas import DataFrame\n",
    "import sys, codecs, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autovivify_list(dict):\n",
    "  '''A pickleable version of collections.defaultdict'''\n",
    "  def __missing__(self, key):\n",
    "    '''Given a missing key, set initial value to an empty list'''\n",
    "    value = self[key] = []\n",
    "    return value\n",
    "\n",
    "  def __add__(self, x):\n",
    "    '''Override addition for numeric types when self is empty'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return x\n",
    "    raise ValueError\n",
    "\n",
    "  def __sub__(self, x):\n",
    "    '''Also provide subtraction method'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return -1 * x\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_word_vector_matrix(vector_file, n_words):\n",
    "  '''Return the vectors and labels for the first n_words in vector file'''\n",
    "  numpy_arrays = []\n",
    "  labels_array = []\n",
    "  with codecs.open(vector_file, 'r', 'utf-8') as f:\n",
    "    for c, r in enumerate(f):\n",
    "      sr = r.split()\n",
    "      labels_array.append(sr[0])\n",
    "      numpy_arrays.append( numpy.array([float(i) for i in sr[1:]]) )\n",
    "\n",
    "      if c == n_words:\n",
    "        return numpy.array( numpy_arrays ), labels_array\n",
    "\n",
    "  return numpy.array( numpy_arrays ), labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_word_clusters(labels_array, cluster_labels):\n",
    "  '''Return the set of words in each cluster'''\n",
    "  cluster_to_words = autovivify_list()\n",
    "  for c, i in enumerate(cluster_labels):\n",
    "    cluster_to_words[ i ].append( labels_array[c] )\n",
    "  return cluster_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=252, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector_file = '/Users/varunnandu/glove/vectors.txt' # Vector file input (e.g. glove.6B.300d.txt)\n",
    "n_words = int(1262) # Number of words to analyze \n",
    "reduction_factor = float(0.2) # Amount of dimension reduction {0,1}\n",
    "n_clusters = int( n_words * reduction_factor ) # Number of clusters to make\n",
    "df, labels_array = build_word_vector_matrix(input_vector_file, n_words)\n",
    "kmeans_model = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans_model.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_labels  = kmeans_model.labels_\n",
    "cluster_inertia   = kmeans_model.inertia_\n",
    "cluster_to_words  = find_word_clusters(labels_array, cluster_labels)\n",
    "\n",
    "clusters = []\n",
    "for c in cluster_to_words:\n",
    "    clusters.append(cluster_to_words[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ['the', 'of', 'is', 'to', 'and', '05', 'in', 'that', 'be', 'as', 'it', 'by', 'are', 'for', 'can', 'this', 'or', 'probability', 'used', 'which', 'an', 'vector', 'pagerank', 'on', 'from', 'classes', 'he', 'has', 'with', 'have', 'page', 'one', 'inheritance', 'each', 'probabilities', 'google', 'also', 'class', 'subproblems', 'number', 'links', 'given', 'we', 'these', 'between', 'more', 'new', 'where', 'if', 'using', 'any', 'methods', 'means', 'at', 'two', 'computer', 'objects', 'been', 'values', 'no', 'there', 'represented', 'same', 'they', 'substructure', 'another', 'derived', 'often', 'based', 'optimization', 'mathematical', 'after', 'models']\n",
      "18      ['programming', 'dynamic']\n",
      "24      ['term', 'occurs']\n",
      "28      ['h0k', 'ubx', 'hhk', 'hij', 'hijses']\n",
      "30      ['all', 'common']\n",
      "32      ['theorem', 'bayes']\n",
      "36      ['document', 'query']\n",
      "38      ['06', '000464908', '000479967', '00152028']\n",
      "40      ['problems', 'method', 'solving']\n",
      "41      ['documents', 'vectors']\n",
      "42      ['optimal', 'problem', 'solutions']\n",
      "44      ['information', 'retrieval']\n",
      "46      ['space', 'model']\n",
      "52      ['terms', 'words']\n",
      "53      ['called', 'sometimes']\n",
      "57      ['not', 'does']\n",
      "59      ['conditional', 'marginal', 'relates']\n",
      "60      ['example', 'could']\n",
      "61      ['other', 'pages', 'web']\n",
      "65      ['may', 'certain', 'observed', 'applied', 'symptoms']\n",
      "66      ['value', 'its', 'importance']\n",
      "71      ['events', 'random']\n",
      "73      ['object', 'word', 'oriented']\n",
      "74      ['about', 'specific', 'stored']\n",
      "75      ['algorithm', 'link', 'analysis']\n",
      "76      ['sub', 'into']\n",
      "77      ['many', 'will', 'how', 'results', 'high', 'linked', 'rank', 'sites']\n",
      "81      ['known', 'such', 'base', 'well']\n",
      "82      ['search', 'internet', 'engine']\n",
      "85      ['solution', 'find']\n",
      "86      ['was', 'first']\n",
      "87      ['8i', '8w', '8e', '8v', '8z', '8j', 'b8', 'l8', 'c8', 'h8', '8l', '8p', 'd8', 'r8', 't8', '8n', 'a8', 'f8', 'x8', '7o', '79', 'j8', '9s', 'see', 'factor', 'possible', 'vote', 'assumptions', 'counts', 'previous']\n",
      "89      ['different', 'but']\n",
      "90      ['then', 'would', 'calculated']\n",
      "91      ['8x', 'p8', 's8', '9e', '8k', '8o', '9m', 'g8', '9h', 'h9', 'u8', '9i', 'o9', '9q', 'since', 'x9', 'q9', '9d', '9o', '95', 'describe', '29', '49', 'dp', 'y9', 'entities', 'i9', 'q7', 'bayesians', 'modules', 'ff', 'processing', 'uh', 'postgraduate', 'transport', 'whole', '1g', 'animals', 'ch', 'content', 'eh', 'fd', 'four', 'get', 'just', 'jz', 'nodes', 'patented', 'pieces', 'public', 'recursively', 'superclasses', 'without']\n",
      "92      ['code', 'their', 'frequencies', 'subsets', 'occurrence']\n",
      "93      ['up', 'time', 'so', 'when', 'computed', 'divided', 'data', 'determine', 'do', 'made', 'out', 'found', 'try', 'manipulation']\n",
      "95      ['8q', 'o8', '8h', '98', '8d', '8f', '8u', '8g', 'y8', 'q8', 'w8', 'z8', '7w', '48', '7p', '38', '7d', '8s', 'b9', '7y', '7k', '7u', 'relationship', 'what', '7t', 'j7', '82', 'generally', 'ja', 'n9', 'zs', '6a', '7l', 'jj', 'second', '8_', 'acts', 'cx', 'df', 'fu', 'jm', 'qd']\n",
      "96      ['student', 'event']\n",
      "97      ['way', 'form']\n",
      "98      ['being', 'identifiers', 'poorly', 'queries', 'systems', 'expressed', 'populations', 'instances', 'proportions']\n",
      "101      ['fruit', 'apple', 'acceptable', 'abstraction']\n",
      "104      ['9j', '9x', '8y', '9p', '9f', '9w', '9l', '9k', '80', '99', '9z', '2099e', '9u', 'j9', '9c', 't9', 'x7', '92', 'apples', 'numerical', '39', '75', 'prob', 'sufficiently', 'circle', 'qx', 'ba', 'below', 'involves', 'numeric', 'our', 'pre', 'smaller', 'yn', '60', 'co', 'described', 'nq', 'qs', 'shape', 'st', 'weight']\n",
      "105      ['compute', 'posterior']\n",
      "106      ['however', 'most', 'important', 'therefore', 'calculate', 'usually', 'allows', 'distribution', 'system', 'useful', 'formula', 'considered']\n",
      "107      ['8b', '8m', 'i8', '8t', '88', '8a', '9g', 'm8', '89', 'n8', '9y', '00141866', '9b', 'c9', 'u9', 'r7', 'p9', '58', '68', '81', '8c', 'a9', '85', '9r', 'e9', 'l9', 'd9', 'f9', 'ir', 'l7', '09', '9_', 'k9', 'm7', 'm9', 'r9', '08', '69', '90', 'a1', 'a7', 'pr', 's9', 'u7', 'z9', '7n', '91', 'e7', 'polymorphism', 'whilst', 'xp', 'bw', 'hg', 'kw', 'ny', 'qw', 'research', 'ro', 'solves', 'very', 'yz', 'z6', '17', '74', '_9', 'bm', 'chance', 'da', 'es', 'features', 'fk', 'functions', 'further', 'fv', 'gb', 'gr', 'greater', 'h6', 'km', 'ku', 'language', 'make', 'mt', 'og', 'pp', 'qj', 'qz', 'ri', 'surfer', 'systemdocument', 'type', 'ui', 'uq', 'yr', 'zp', '<unk>']\n",
      "108      ['inherit', 'attributes']\n",
      "109      ['use', 'structure', 'uses', 'name', 'kind']\n",
      "110      ['properties', 'overlapping', 'process', 'say', 'exhibit']\n",
      "111      ['9n', '9v', '69545e', 'orange', 'etc', 'down', 'top', 'de', 'context', 'conversely', 'reciprocal']\n",
      "112      ['theory', 'prior']\n",
      "114      ['9t', 'element', 'advantage', 'hence', 'calculating', 'seed', 'uncertainty', 'angles', 'givenis', 'happening']\n",
      "115      ['because', 'generalization']\n",
      "116      ['both', 'beliefs', 'subclasses', 'degrees', 'unique', 'types', 'behavior', 'behaviours']\n",
      "117      ['program', 'categorization', 'support', 'representation', 'exhibition', 'thus', 'synonym']\n",
      "118      ['set', 'hyperlinked']\n",
      "119      ['some', 'overall', 'patient', 'won', 'associated', 'even', 'relation', 'save', 'cases']\n",
      "120      ['computing', 'take', 'account', 'cognitive', 'f4', 'product', 'train', 'large', 'references', 'car', 'discuss', 'engineering', 'mango', 'quotations']\n",
      "123      ['best', 'needs', 'decisions']\n",
      "125      ['non', 'vocabulary', 'zero', 'several', 'frequency']\n",
      "126      ['order', 'keyword', 'concept', 'graph', 'equal', 'originally', 'appear', 'invented', 'lost']\n",
      "127      ['bayesian', 'frequentist']\n",
      "128      ['existing', 'reuse']\n",
      "130      ['similar', 'share', 'lot', 'interfaces']\n",
      "131      ['solve', 'need', 'you']\n",
      "132      ['ways', 'result', 'describes', 'applications', 'recursive']\n",
      "133      ['already', 'defined', 'weights', 'developed']\n",
      "134      ['approach', 'them', 'others', 'extend', 're', 'cannot', 'chosen', 'consider']\n",
      "137      ['particular', 'connection']\n",
      "138      ['solved', 'variables', 'themselves', 'updated']\n",
      "139      ['depends', 'application', 'around', 'debate', 'similarities', 'upon', 'scale', 'specified']\n",
      "140      ['instance', 'action', 'produced']\n",
      "141      ['keywords', 'single', 'longer', 'phrases']\n",
      "142      ['like', 'site', 'bellman', 'patent', 'ranking', 'algorithms', 'meaning', 'webpage', 'denotes', 'articles', 'influence', 'modern', 'through']\n",
      "144      ['000222005', '000641574', '000782035', '00145284']\n",
      "145      ['000714138', '00116851', '00166282']\n",
      "146      ['000837489', '00078398', '00154063']\n",
      "147      ['00105573', '000218071', '000346468', '000722866', '00118384', '00122644', '98124e']\n",
      "148      ['00127245', '00027091', '00127034']\n",
      "149      ['ancestor', 'exposed', 'those', 'adding']\n",
      "150      ['false', 'negative']\n",
      "151      ['instead', 'science', 'languages', 'mathematics']\n",
      "152      ['k8', '87', 'v8', '84', '7v', '97', 'v9', 'w7', '28', '78', '7a', '7q', '7r', '8r', '7f', '7z', 'v7', '18', '7c', '7h', 'e8', 'f7', 'g9', 'y7', '7b', '7g', '7i', '86', '9a', 'collection', 'i7', 'main', '19', '6m', '7e', '7s', '7x', '83', '_8', '10', '77', '7m', 'available', 'c7', 'g7', 'h7', 'key', 'z7', '59', '6b', '6v', '72', '7_', 'b7', 'following', 'k7', 'n7', 'om', 'w9', '6e', '73', '76', '96', 'ae', 'basically', 'dx', 'fs', 'ht', 'idea', 'lg', 'md', 'memoization', 'popular', 'ra', 'rd', 'rj', 'ss', 'zn', '37', '4e', '5x', '67', '6i', '6l', '6r', '70', '93', 'ac', 'accurate', 'again', 'bd', 'd6', 'd7', 'dc', 'evidence', 'fi', 'fj', 'formed', 'g6', 'h1', 'hc', 'ii', 'il', 'inherited', 'io', 'iv', 'j6', 'kf', 'kx', 'lt', 'measure', 'qf', 'together', 'un', 'vl', 'wa', 'wz', 'xl', 'xt', 'ya']\n",
      "153      ['original', 'within', 'cosine', 'dimensionality', 'angle']\n",
      "154      ['plan', 'finding', 'sense']\n",
      "155      ['superclass', 'only', 'subclass']\n",
      "156      ['than', 'naive', 'bottom', '7j', 'hijubx', 'university', 'comes', 'must', 'rq', 'shortest', 'stanford', 'f5', 'had', 'naturally', 'rh', 'ru', 'gi', 'qu', 'refined', 'rz', 'sn', 'storing', 'us']\n",
      "157      ['weighting', 'path', 'higher', 'characteristics', 'your', 'factors', 'goal', 'visits', 'among', 'website', 'affect']\n",
      "158      ['000104496', '000349485', '0015882', '0015892']\n",
      "159      ['000112297', '000510361', '000822361', '000970411', '00112897']\n",
      "160      ['000118776', '0002997', '000379887', '000767073']\n",
      "161      ['000121415', '000251048', '000289281', '000419433', '000741238']\n",
      "162      ['000121931', '00132224', '00163446']\n",
      "163      ['000128402', '000997195', '00123337', '00159539']\n",
      "164      ['000146166', '000228113', '00160403']\n",
      "165      ['000149611', '000342545', '000717298', '7908e', '07']\n",
      "166      ['000154344', '000597976', '0014425', '0015844']\n",
      "167      ['000154858', '000740185', '00122127', '00158507']\n",
      "168      ['000173975', '000281587', '000434826', '000997342', '00134573', '00138859', '00147126']\n",
      "169      ['000176249', '000664931', '000923061', '0011547', '00150916']\n",
      "170      ['000204662', '000233989', '000454297', '00132652', '00162791']\n",
      "171      ['000208043', '000254484', '000486314', '00130591', '00148223', '28277e']\n",
      "172      ['000209893', '000468307', '000658771', '00146592']\n",
      "173      ['000213784', '000228605', '00044146', '000507011', '00132182']\n",
      "174      ['000218611', '000407494', '000627347', '000654478', '00106799']\n",
      "175      ['000226815', '000388528', '000972417', '00154554', '63164e']\n",
      "176      ['000230336', '000309389', '0010244', '00116003']\n",
      "177      ['000233216', '000247751', '000302909', '000510669']\n",
      "178      ['000237438', '000672392', '00121509']\n",
      "179      ['00024084', '000253858', '000306806']\n",
      "180      ['000253155', '00106998', '00112648', '001343', '00134634']\n",
      "181      ['000253817', '000354644', '00160269']\n",
      "182      ['000257429', '000404928', '000658096', '000873691', '00111769', '00143611', '00144738']\n",
      "183      ['00028446', '000784815', '000914112']\n",
      "184      ['00028579', '000606723', '000679533', '00127091']\n",
      "185      ['000288034', '000727566', '00145348']\n",
      "186      ['000288376', '00070198', '000721091', '00105603', '00159964']\n",
      "187      ['00029439', '000429939', '00110349', '00124217']\n",
      "188      ['000339263', '00062685', '000967188', '00104602', '00148124']\n",
      "189      ['000344981', '00067521', '00104599']\n",
      "190      ['000373652', '00038978', '000392118', '00147916']\n",
      "191      ['000385199', '00112502', '00122709', '00125393']\n",
      "192      ['000388454', '000599943', '000798503', '000861262', '00159783', '1804e']\n",
      "193      ['000392922', '000509222', '00117286', '0016061', '00162254']\n",
      "194      ['000393385', '000533912', '000661417', '000699741']\n",
      "195      ['000437583', '00101139', '00120606']\n",
      "196      ['000438051', '000481291', '00103384', '00107373', '00121033', '00125502', '00159165', '74935e', '77299e']\n",
      "197      ['000466403', '000935097', '00118882', '00127242']\n",
      "198      ['00046674', '00118601', '00162762']\n",
      "199      ['000515494', '000681381', '000920251', '00142694', '00156054']\n",
      "200      ['000521099', '000851915', '00113677', '00129875']\n",
      "201      ['00053947', '000828879', '000884418', '000894328', '00146811', '00149773', '00153857']\n",
      "202      ['000543594', '000788925', '000943677', '0009751', '00158112']\n",
      "203      ['000555889', '000568793', '000615239', '000965391', '00123691']\n",
      "204      ['000558035', '00060477', '00122734', '00143099']\n",
      "205      ['000566388', '00095051', '00143176', '0016119']\n",
      "206      ['000592722', '00076664', '00109647', '00165102']\n",
      "207      ['000606068', '000624961', '00075486', '000993489', '00104788', '00150931']\n",
      "208      ['000641772', '000750848', '41461e']\n",
      "209      ['000679629', '00102065', '00130641', '00133258', '00139828']\n",
      "210      ['000689932', '000692842', '000863904', '00116315', '00124763', '00133235', '00153979']\n",
      "211      ['000723977', '000797545', '00126601', '00153604']\n",
      "212      ['000766635', '00109457', '0122e']\n",
      "213      ['000769519', '000948308', '00149124']\n",
      "214      ['000818812', '000908618', '00147324']\n",
      "215      ['000820195', '000955627', '0669e']\n",
      "216      ['000918943', '00120731', '00134052', '00135353', '0015764', '000295394']\n",
      "217      ['000927189', '00110873', '00137624', '00142988', '00159927']\n",
      "218      ['000978992', '00100001', '00148554', '00160493']\n",
      "219      ['00121285', '00127489', '79304e']\n",
      "221      ['general', 'referred', 'seen']\n",
      "222      ['interpretations', 'trousers', 'central', 'takes', 'role', 'students', 'equation', 'field', 'mechanism', 'wear', 'debates', 'occurring', 'shares', 'vanishing']\n",
      "223      ['less', 'rankings', 'smart']\n",
      "224      ['world', 'wide']\n",
      "225      ['assigned', 'should']\n",
      "226      ['assigns', 'observations', 'simple', 'case', 'yo', 'design', 'technique', 'who']\n",
      "227      ['hierarchy', 'represent', 'relationships']\n",
      "228      ['match', 'positive', 'disagree', 'might', 'matches', 'precisely', 'entity', 'frequentists', 'reach', 'substrings']\n",
      "229      ['similarity', 'poor', 'small']\n",
      "230      ['child', 'little', 'over', 'parent']\n",
      "231      ['either', 'accomplished', 'dividing', 'overriding', 'replacing']\n",
      "232      ['f2', 'much', 'f3', 'view', 'economy', 'dual', 'f1', 'weightingthe']\n",
      "233      ['tf', 'idf', 'schemes']\n",
      "234      ['typically', 'plays', 'topic', 'girl', 'popularity', 'wearing', 'computation', 'happened', 'modification', 'right', 'theoretical', 'true']\n",
      "235      ['according', 'assign']\n",
      "236      ['dimension', 'separate', 'corresponds']\n",
      "238      ['relative', 'definition', 'statistics', 'complexity', 'measuring', 'reducing', 'foundations', 'purpose', 'total', 'distinct']\n",
      "239      ['representing', 'text', 'algebraic']\n",
      "240      ['indexing', 'relevancy', 'filtering']\n",
      "241      ['step', 'three']\n",
      "242      ['actual', 'subproblem', 'having', 'users', '1940s', 'engines', 'include', 'relevance', 'relevant', 'toolbar', 'comparing', 'normally', 'provided', 'specialised']\n",
      "243      ['diagnosis', 'correct', 'proposed', 'formal']\n",
      "244      ['every', 'help', 'larger', 'needed', 'intended', 'create', 'due', 'group', 'access', 'add', 'said']\n",
      "245      ['provides', 'basic', 'powerful', 'valid', 'constant', 'appears', 'remembered', 'solvable']\n",
      "246      ['until', 'clicking', 'person', 'randomly']\n",
      "247      ['control', 'learning', 'richard', 'shared', 'controlled', 'human', '1953']\n",
      "248      ['index', 'container', 'fleshy', 'long']\n",
      "249      ['schedule', 'finalized']\n",
      "250      ['thomas', 'law', 'rev']\n",
      "251      ['inbound', 'outbound']\n"
     ]
    }
   ],
   "source": [
    "clust_dict = {}\n",
    "for clus in clusters:\n",
    "    if len(clus) == 1:\n",
    "        if 0 not in clust_dict:\n",
    "            clust_dict[0] = clus\n",
    "        else:\n",
    "            clust_dict[0] += clus\n",
    "    else:\n",
    "        clust_dict[clusters.index(clus)] = clus\n",
    "for key, value in clust_dict.items():\n",
    "    print(key, '    ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, nltk, re\n",
    "\n",
    "# Open a file\n",
    "path = \"/Users/varunnandu/Desktop/plagiarism-detection-nlp/DATA-NLP\"\n",
    "dirs = os.listdir( path )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_mapping = dict() # Mapping to question dictionary\n",
    " # Mapping to student as key and answer as value\n",
    "\n",
    "for file in dirs:\n",
    "    if file == '.DS_Store':\n",
    "            continue\n",
    "    path_to_file='/Users/varunnandu/Desktop/plagiarism-detection-nlp/DATA-NLP/'\n",
    "    file_name = file\n",
    "    split_name = file.split('_')\n",
    "    student_name = split_name[0]\n",
    "    question_number = split_name[1].split('.')[0]\n",
    "    if question_number not in question_mapping:\n",
    "        question_mapping[question_number] = {}\n",
    "    path_to_file += file_name\n",
    "    with open(path_to_file, 'r', errors = 'ignore') as f:\n",
    "        mylist = f.read()\n",
    "        sent_tokenize_list = nltk.sent_tokenize(mylist)\n",
    "        temp = []\n",
    "        for i in sent_tokenize_list:\n",
    "            sent = i.lower()\n",
    "            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "            temp.append(sent)\n",
    "        question_mapping[question_number][student_name] = temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskc      {'g0pC': [[0, 0, 46, 46, 0, 0, 0, 36, 0, 0, 0, 52, 0, 0, 126, 0, 230], [0, 36, 0, 0, 0, 0, 73, 0, 236], [0, 0, 0, 90, 0, 0, 125, 0, 73, 236], [0, 0, 0, 134, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 0, 131, 0, 0, 153, 229, 0, 157, 0, 41], [0, 77, 85, 0, 0, 0, 0, 41, 0, 120, 0, 0, 134], [0, 36, 0, 82, 46, 0, 36, 0, 0, 0, 0, 0, 0, 90, 131, 85, 0, 36, 0, 0, 0, 153, 139, 0, 157, 36], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 119, 0, 0, 134, 120, 0, 153, 139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 42, 131, 0, 109, 0, 90, 0, 0, 0], [0, 111]], 'g0pE': [[0, 117, 0, 118, 0, 41, 0, 41, 0, 30, 0, 46, 0, 81, 0, 0, 0, 46, 0, 46, 46, 0, 0, 0, 0, 44, 44, 107, 41, 0, 36, 36, 0, 36, 0, 86, 0, 245, 0, 46, 241, 0, 0, 0, 0, 232, 0, 98, 0, 41, 0, 0, 0, 0, 46, 0, 0, 36, 152]], 'g1pA': [[0, 0, 46, 46, 0, 0, 239, 46, 0, 0, 227, 239, 41, 0, 0, 0, 95, 0, 41, 0, 98, 0, 140, 248, 52], [66, 132, 242, 44, 240, 44, 44, 240, 0, 240, 223], [0, 0, 0, 46, 41, 0, 0, 0, 41], [0, 236, 236, 0, 236, 24], [0, 66, 0, 0, 0, 125, 125, 0, 24, 24, 0, 0, 36], [125, 89, 132, 0, 0, 133, 0, 114, 0, 0, 0, 81, 0, 24, 133], [0, 0, 0, 123, 81, 233, 0, 233, 233, 24, 125, 36, 125, 157], [0, 46, 0, 0, 0, 0, 93, 0, 240, 223, 0, 41, 0, 126, 82, 0, 0, 87, 0, 36, 139, 112, 0, 242, 0, 153, 36, 0, 0, 0, 36, 0, 0, 0, 0, 109, 0, 0, 0, 0, 41, 0, 0, 0, 114, 0, 0, 36, 0], [0, 0, 46, 46, 86, 0, 0, 0, 0, 81, 0, 24, 125, 36, 125, 46], [0, 0, 46, 0, 24, 74, 133, 0, 0, 36, 41, 0, 0, 0], [0, 24, 46, 0, 24, 74, 133, 0, 91, 0, 87, 0, 24, 0, 106, 93, 57, 242, 0]], 'g3pB': [[0, 0, 120, 0, 0, 0, 0, 0, 40, 0, 42, 0, 44, 44, 0, 0, 0, 30, 0, 0, 0, 0, 241, 0, 118, 112, 0], [0, 0, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 239, 46], [0, 0, 0, 46, 46, 36, 0, 0, 0, 0], [153, 0, 0, 0, 236, 236, 0, 236, 24, 0, 24, 0, 234, 141, 73, 126, 0], [0, 0, 24, 153, 0, 36, 0, 66, 0, 0, 0, 0, 125], [0, 24, 24, 0, 0, 36, 66, 66, 0, 125, 125], [0, 106, 77, 242, 0, 36, 0, 0, 126, 82, 0, 153, 66, 0, 0, 153, 0, 0, 41, 0, 0, 106, 151, 0, 0, 242, 153], [0, 0, 46, 46, 106, 0, 57, 91, 66, 0, 0, 229, 229, 0, 248, 41, 0, 98, 0, 0, 126, 0, 52, 57, 57, 150, 228, 228, 65, 0, 74, 0, 52, 153, 52, 138, 0, 41, 0, 225, 228, 89, 109, 89, 65, 150, 150, 228], [0, 0, 0, 0, 61, 0, 0, 0, 0, 0, 0, 134, 0, 0, 46, 46, 0, 0, 0, 0, 93, 0, 0, 40]], 'g0pB': [[0, 46, 46, 0, 0, 239, 46, 0, 239, 239, 41, 0, 0, 221, 0, 0, 0, 41, 0, 98, 81, 0, 0, 60, 248, 52], [66, 86, 109, 86, 0, 0, 223, 44, 44, 106], [0, 0, 0, 0, 44, 240, 44, 44, 240, 0, 240, 223], [36, 0, 0, 0, 0, 0, 0, 236, 236, 0, 236, 24], [0, 24, 24, 0, 0, 36, 66, 66, 0, 0, 0, 0, 125, 125], [125, 89, 132, 0, 120, 0, 0, 0, 81, 0, 24, 133, 0, 0, 133], [0, 238, 0, 24, 139, 0, 0, 139], [234, 52, 0, 141, 52, 141, 0, 141, 141], [0, 0, 52, 0, 134, 0, 0, 0, 52, 0, 153, 0, 0, 0, 0, 0, 0, 0, 52, 0, 0, 125, 0, 0, 0, 238, 52, 222, 0, 0], [0, 0, 0, 123, 81, 233, 0, 233, 233, 157, 243, 0, 0], [0, 0, 0, 46, 46, 0, 24, 74, 133, 0, 0, 36, 41, 0, 0, 0], [240, 223, 0, 41, 0, 126, 82, 0, 0, 90, 0, 0, 87, 0, 36, 139, 112, 0, 242, 0, 0, 114, 0, 0, 36, 0, 0, 0, 153, 36, 0, 0, 0, 36, 0, 0, 0, 0, 109, 0, 0, 0, 0, 41], [0, 0, 46, 46, 0, 0, 152, 82, 141, 156, 228, 228, 36, 52, 73, 228, 228, 132, 0, 150, 228, 228, 41, 0, 130, 111, 89, 89, 24, 125, 119, 0, 119, 0, 150, 150, 228, 0, 126, 0, 0, 0, 52, 126, 0, 0, 36, 0, 126, 0, 0, 0, 46, 117, 248, 41, 0, 98, 0, 115, 0, 0, 229, 229, 0, 229, 120, 0, 120, 153]], 'g2pA': [[0, 46, 46, 0, 24, 0, 46, 0, 0, 239, 97, 0, 239, 239, 41, 0, 0, 0, 0, 221, 0, 41, 0, 98, 81, 0, 248, 52], [0, 0, 0, 0, 44, 240, 44, 44, 240, 0, 240, 223], [66, 86, 139, 86, 0, 0, 223, 44, 44, 106], [36, 0, 0, 0, 0, 0], [244, 236, 59, 0, 89, 24], [0, 24, 245, 0, 0, 36, 0, 52, 66, 0, 0, 0, 0, 125, 125], [77, 89, 0, 0, 114, 0, 0, 53, 81, 0, 24, 133, 0, 0, 133], [233, 233, 157, 0, 0, 0, 0, 106, 81, 81, 233], [87, 104, 60], [0, 238, 0, 24, 139, 0, 0, 139], [242, 24, 0, 141, 73, 126, 0, 141], [0, 0, 52, 0, 134, 0, 0, 0, 52, 0, 153, 0, 0, 0, 0, 0, 0, 0, 52, 0, 0, 125, 0, 0, 0, 238, 52, 222, 0, 0], [0, 0, 46, 46, 0, 119], [141, 41, 0, 0, 98, 115, 0, 41, 0, 229, 229, 0, 229, 120, 0, 120, 153], [82, 141, 0, 0, 228, 228, 36, 52, 73, 228, 60, 132, 0, 150, 228, 228], [41, 0, 130, 111, 89, 89, 24, 125, 119, 0, 119, 0, 150, 150, 228], [], [0, 126, 0, 0, 52, 126, 0, 0, 36, 0, 126, 0, 0, 46, 117]], 'g0pD': [[0, 239, 46, 0, 239, 239, 41, 0, 0, 0, 0, 221, 0, 81, 0, 0, 109, 0, 46, 46], [0, 0, 0, 41, 0, 98, 248, 52, 0, 0, 0, 0], [0, 0, 46, 46, 86, 86, 0, 0, 0, 223, 44, 44, 106, 0, 0, 0, 0, 240, 44, 240, 240, 0, 44, 44], [36, 0, 117, 0, 0], [244, 236, 0, 228, 0, 236, 24], [0, 97, 0, 0, 24, 0, 133, 139, 0, 0, 139, 234, 52, 0, 231, 141, 52, 141, 0, 141, 141], [0, 153, 0, 0, 0, 0, 0, 0, 0, 52, 0, 0, 125, 0, 0, 0, 0, 52, 0, 0, 0, 0, 0, 52], [93, 0, 0, 0, 141, 0, 141, 141], [0, 24, 24, 0, 0, 36, 66, 66, 0, 0, 0, 0, 125, 125], [125, 89, 132, 0, 120, 0, 0, 81, 0, 24, 133, 0, 0, 133], [0, 0, 0, 106, 233, 0, 233, 233, 157]], 'orig': [[0, 46, 46, 0, 24, 0, 46, 0, 0, 239, 46, 0, 239, 239, 41, 0, 0, 0, 0, 221, 0, 41, 0, 98, 81, 0, 0, 60, 248, 52], [0, 0, 0, 0, 44, 240, 44, 44, 240, 0, 240, 223], [66, 86, 109, 86, 0, 0, 223, 44, 44, 106], [36, 0, 0, 0, 0], [0, 236, 236, 0, 236, 24], [0, 24, 24, 0, 0, 36, 66, 66, 0, 0, 0, 0, 125, 125], [125, 89, 132, 0, 120, 0, 0, 0, 81, 0, 24, 133, 0, 0, 133], [0, 0, 0, 123, 81, 233, 0, 233, 233, 157, 87, 0, 60, 104], [0, 238, 0, 24, 139, 0, 0, 139], [234, 52, 0, 141, 52, 141, 0, 141, 141], [0, 0, 52, 0, 134, 0, 0, 0, 52, 0, 153, 0, 0, 0, 0, 0, 0, 0, 52, 0, 0, 125, 0, 0, 0, 238, 52, 222, 0, 0], [0, 0, 46, 46, 0, 0, 152], [248, 41, 0, 98, 0, 115, 0, 0, 229, 229, 0, 229, 120, 0, 120, 153], [82, 141, 156, 228, 228, 36, 52, 73, 228, 228, 132, 0, 150, 228, 228], [41, 0, 130, 111, 89, 89, 24, 125, 119, 0, 119, 0, 150, 150, 228], [], [0, 126, 0, 0, 0, 52, 126, 0, 0, 36, 0, 126, 0, 0, 0, 46, 117]], 'g3pC': [[0, 0, 0, 46, 46, 0, 44, 44, 0, 30, 61, 0, 98, 0, 77, 41], [0, 0, 0, 0, 89, 126], [0, 0, 61, 0, 36, 0, 0, 0, 0, 93, 0, 0, 120, 106, 0, 85, 0, 153, 0, 134], [0, 0, 153, 0, 134, 89, 0, 46], [77, 77, 0, 0, 0, 98, 228], [242, 0, 41, 77, 57, 0, 0, 150, 0, 93, 77, 77, 0, 107, 156, 0, 126, 0], [0, 153, 0, 93, 0]], 'g2pB': [[0, 46, 46, 0, 0, 239, 46, 0, 239, 239, 41, 0, 41, 0, 98], [87, 109, 0, 0, 46, 46, 0, 0, 44, 0, 240, 0, 44], [61, 87, 109, 0, 0, 46, 0, 0, 240, 0, 0, 0, 77, 0, 240, 0, 41], [0, 107, 0, 46, 0, 152, 36, 0, 0, 0], [0, 0, 236, 24, 0, 0], [0, 0, 0, 132, 0, 0, 105, 0, 89, 87, 0, 0, 0, 46, 0, 0, 0, 106, 98, 0, 233, 233, 157], [0, 139, 0, 142, 0, 95, 0, 238, 0, 0, 24, 0], [24, 0, 106, 141, 73, 141, 0, 141, 141], [0, 0, 0, 116, 52, 0, 0, 125, 142, 0, 153, 0, 52, 0, 0, 0, 0, 52], [106, 107, 0, 46, 0, 106, 0, 0, 152, 40, 0, 0, 0, 0, 0, 0, 0, 126, 0, 0, 52, 0, 126, 141, 156, 0, 0, 0, 41, 0, 229, 229, 66, 244, 0, 98, 98, 0, 0, 0, 41, 0, 0, 0, 0, 234, 0, 119, 0, 24, 125]], 'g0pA': [[0, 0, 46, 46, 0, 53, 24, 0, 46, 0, 0, 239, 46, 0, 0, 227, 239, 41, 0, 81, 0, 0, 0, 0, 221, 0, 41, 0, 98], [0, 0, 0, 0, 44, 44, 0, 86, 86, 0, 0, 0, 223, 44, 44, 106], [36, 0, 0, 0, 0, 0, 0, 236, 236, 0, 236, 24], [0, 24, 245, 0, 0, 36, 90, 66, 66, 0, 0, 0, 0, 125, 125], [77, 89, 132, 0, 114, 0, 0, 0, 81, 0, 24, 133, 0, 0, 133], [0, 0, 0, 123, 81, 0, 0, 53, 233, 233, 157], [0, 238, 0, 24, 139, 0, 0, 139, 89, 95, 52, 0, 141, 52, 141, 0, 141, 141], [0, 0, 52, 0, 134, 0, 0, 0, 52, 0, 153, 0, 0, 0, 0, 0, 0, 0, 52, 0, 0, 125, 0, 0, 0, 0, 0, 238, 52, 222, 0, 0], [0, 0, 46, 46, 0, 125], [248, 41, 0, 0, 115, 0, 0, 229, 229, 0], [82, 141, 156, 228, 36, 52, 0, 228, 0, 52, 228, 132, 0, 150, 228, 228], [41, 0, 130, 111, 89, 89, 24, 125, 77, 57, 0, 119, 0, 150, 150, 228], [0, 126, 0, 0, 0, 52, 126, 0, 0, 36, 0, 126, 0, 0, 0, 46, 117]], 'g4pC': [[0, 0, 46, 46, 0, 0, 41, 0, 0, 0, 0, 0, 52, 0, 245, 152, 0, 0, 227, 0, 36, 0, 0, 0, 65, 73, 92], [0, 126, 0, 93, 93, 0, 152, 0, 0, 244], [], [226, 30, 116, 52, 0, 0, 118, 0, 41], [], [125, 91, 81, 0, 0, 0, 111], [0, 0], [], [0, 0, 36, 0, 0, 0, 0, 0, 73], [], [0, 0, 44, 125, 91, 77, 125, 0, 125, 52], [], [0, 0, 116, 52], [235, 116, 0, 0, 0, 0, 73, 0, 116, 0, 0, 0, 0, 36]], 'g4pE': [[0, 238, 0, 24, 139, 0, 0, 139], [234, 52, 0, 141, 52, 141, 0, 141, 141], [0, 0, 52, 0, 134, 0, 0, 0, 52, 0, 153, 0, 0, 0, 0, 0, 0, 0, 52, 0, 0, 125, 36, 0, 0, 0, 0], [0, 236, 0, 236, 52], [0, 24, 24, 0, 0, 36, 66, 66, 0, 0, 0, 0, 125, 125], [240, 223, 0, 41, 0, 126, 82, 0, 0, 90, 0, 0, 87, 0, 36, 139, 112, 0, 242, 0, 0, 114, 0, 0, 36, 0, 0, 0, 153, 36, 0, 0, 0, 36, 0, 0, 0, 0, 109, 0, 0, 0, 0, 41], [0, 0, 119, 0, 0, 46, 46], [0, 0, 0, 0, 0, 0, 46, 46, 242, 0, 46, 46], [234, 0, 0, 46, 46, 0, 0, 46, 46, 0, 0, 0, 0, 24, 41, 0], [0, 0, 0, 0, 46, 46, 0, 234, 0, 0, 46, 46, 57, 57, 0, 0, 139, 0, 52], [0, 0, 0, 234, 0, 0, 46, 46, 0, 0, 57, 0, 0, 0, 77, 0, 24, 41, 0, 0]], 'g2pC': [[0, 0, 0, 46, 46, 41, 120, 0, 97, 0, 0, 52, 44, 44, 134, 0, 41, 0, 0, 0, 109, 95, 52, 0, 0, 77, 0, 0], [0, 0, 46, 46, 0, 0, 0, 44, 44, 0, 93, 77, 130, 41, 0, 0, 0, 0, 0, 77, 130, 41, 0, 0, 82, 36], [0, 152, 0, 41, 0, 36, 0, 0, 0, 0, 0, 0, 0, 52, 0, 0, 36, 0, 0, 24, 0, 0], [98, 0, 0, 0, 0, 0, 41, 0, 0, 0, 46, 46, 0, 93, 0, 36, 228, 0, 36, 0, 0, 0, 36, 0, 0, 0, 0, 0, 36, 0], [0, 36, 0, 0, 0, 0, 36, 0, 0, 0, 0, 229, 152, 0, 0, 0, 153, 0, 0, 153, 0, 0, 36, 0, 0, 0, 36, 0], [0, 222, 0, 90, 0, 231, 0, 120, 0, 0, 36, 0, 0, 0, 36, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 36, 0], [0, 222, 76, 120, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [36, 0, 153, 229, 0, 106, 0, 0, 0, 36, 0, 0, 36]], 'g4pB': [[0, 0, 46, 46, 0, 24, 0, 46, 0, 0, 239, 46, 0, 239, 239, 41, 0, 0, 0, 0, 221, 0, 41, 0, 98, 81, 0, 248, 52], [0, 0, 0, 0, 44, 240, 44, 44, 240, 0, 240, 223], [0, 86, 0, 0, 0, 86, 93, 0, 0, 223, 44, 44, 106], [36, 0, 0, 0, 0], [0, 0, 244, 236, 236, 0, 236, 24], [0, 24, 0, 36, 66, 66, 0, 0, 0, 0, 57, 126, 0, 125], [0, 89, 142, 0, 120, 0, 0, 0, 81, 0, 24, 133, 0, 0], [0, 0, 0, 106, 152, 233, 0, 233, 233, 157], [0, 238, 0, 24, 0, 0, 0, 139], [234, 52, 0, 141, 141, 52, 0, 141, 141], [242, 0, 52, 0, 0, 0, 0, 52, 0, 153, 0, 0, 0, 0, 126, 0, 0, 0, 0, 52, 0, 0, 125], [0, 0, 0, 106, 0, 0, 0, 153, 0, 0, 41, 151, 0, 0, 153, 0, 0, 106, 66, 0, 0, 36, 0, 36, 0, 0, 156, 0, 228, 0, 0, 0, 0, 24, 0, 0, 36, 86, 0, 0, 36]], 'g1pD': [[153, 44, 44, 0, 36, 0, 118, 0, 0, 0, 0, 0, 77, 0, 46, 0, 117, 0, 53, 0, 0, 46, 46], [44, 44, 98, 0, 0, 0, 0, 41, 0, 0, 0, 0, 46, 0, 0, 90, 0, 0, 0, 0, 36, 41, 0, 85, 242, 41], [0, 0, 41, 0, 0, 0, 41, 0, 157, 36, 36, 229, 0, 157, 0, 52, 0, 242], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 41, 0, 106, 0, 40, 0, 0, 0, 46, 46, 0, 0, 153, 0, 0, 153, 0, 0, 0, 41, 0, 66, 0, 0]], 'g4pD': [[0, 0, 46, 46, 0, 41, 0, 0, 0, 44, 0, 0, 0, 0, 0, 0, 41], [0, 24, 157, 0, 0, 0, 0, 0, 46, 40], [52, 0, 152, 0, 52, 0, 0, 240, 0, 0, 0, 0, 239], [24, 157, 234, 0, 106, 222, 0, 0, 229, 152], [0, 229, 0, 44, 0, 137, 44, 44, 106], [0, 139, 0], [0, 0, 155, 0, 0, 92, 153, 0, 36, 0, 0, 57, 0, 36, 92], [0, 152, 0, 0, 0, 0, 106, 244, 73, 0, 245, 0, 36, 126, 242], [0, 0, 0, 106, 93, 0, 0, 0, 73, 245, 0, 57, 106, 106], [24, 125, 0, 106, 87, 77, 77, 0, 24, 24, 0, 36], [0, 0, 24, 24, 0, 36, 0, 0, 0, 0, 0, 0, 242, 0, 0, 36], [0, 30, 52, 0, 248, 41], [0, 106, 0, 0, 52, 0, 245, 0, 89, 0, 232], [24, 125, 0, 106, 0, 0, 0, 73, 0, 245, 0, 90, 119, 0, 52, 0, 126], [24, 125, 0, 97, 0, 111, 0, 0, 125], [0, 0, 0, 106, 0]], 'g2pE': [[44, 107, 0, 0, 151, 0, 0, 41, 0, 44, 153, 41, 0, 0, 74, 41, 0, 81, 0, 0, 0, 0, 0, 224, 224, 61], [107, 0, 0, 0, 0, 151, 151, 151, 44, 151, 44, 120, 238, 0], [0, 0, 0, 0, 0, 0, 52, 93, 44, 36, 44, 44, 44, 0, 239, 44, 89, 0, 0, 0, 66, 0, 112, 0], [44, 44, 98, 0, 0, 0, 95, 0, 0, 53, 44], [77, 0, 91, 109, 107, 98, 0, 244, 0, 0, 61, 41]], 'g3pA': [[0, 46, 46, 0, 24, 0, 46, 0, 0, 0, 0, 81, 0, 0, 239, 46, 0, 239, 0, 0, 0, 0, 0, 239, 41, 0, 41, 0, 98, 0, 60, 248, 52], [0, 0, 0, 0, 44, 44, 0, 240, 240, 0, 240, 223, 0, 86, 86, 0, 0, 0, 223, 44, 44, 106], [36, 0, 0, 0, 0, 0, 0, 236, 0, 236, 24], [0, 24, 24, 0, 0, 36, 0, 66, 77, 0, 125, 125, 0, 0, 0], [77, 89, 132, 0, 120, 0, 0, 24, 133, 0, 0, 133, 0, 0, 0, 123, 81, 233, 0, 233, 233, 157], [0, 97, 0, 24, 0, 133, 139, 0, 0, 139], [234, 52, 0, 141, 52, 141, 0, 53, 119, 141, 141], [0, 0, 52, 0, 134, 0, 0, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 238, 52, 0, 0], [240, 0, 41, 0, 126, 82, 0, 0, 90, 0, 109, 0, 87, 0, 36, 139, 112, 0, 242, 0, 0, 114, 0, 0, 36, 0, 0, 0, 153, 36, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 41], [95, 0, 0, 0, 106, 0, 153, 0, 0, 153, 0, 0, 41, 151, 0, 0, 153], [125, 66, 0, 0, 153, 0, 0, 36, 0, 36, 0, 0, 0, 93, 156, 0, 228, 0, 0, 0, 36, 24, 57, 0, 0, 36, 98, 106], [106, 0, 0, 46, 46, 0], [248, 41, 0, 98, 0, 244, 0, 92, 229, 229, 0, 229, 120, 0, 120, 153, 82, 141, 156, 228, 228, 0, 36, 52, 73, 228, 228, 132, 0, 150, 228, 228, 130, 111, 41, 89, 89, 24, 125, 119, 0, 119, 0, 150, 150, 228, 0, 0, 126, 0, 0, 52, 126, 0, 0, 36, 0, 57, 0, 0, 0, 0, 46, 46]], 'g1pB': [[0, 239, 46, 0, 239, 239, 41, 0, 0, 0, 41, 0, 98, 0, 53, 0, 0, 46, 46], [0, 0, 0, 0, 44, 240, 240, 240, 223, 0, 44, 44], [0, 86, 86, 0, 0, 0, 223, 44, 44, 106], [93, 36, 0, 0, 0, 0, 0, 236, 236, 0, 236, 24], [24, 0, 24, 0, 0, 36, 0, 66, 0, 0, 0, 0, 125, 125], [61, 132, 0, 120, 0, 0, 0, 133, 0, 0, 133], [0, 106, 152, 0, 233, 233, 157], [0, 0, 139, 0, 238, 0, 24], [141, 52, 141, 0, 141, 141, 0, 0, 0, 52], [0, 153, 0, 0, 0, 0, 52, 0, 0, 0, 52, 0, 0, 238, 0, 0, 52, 152, 0, 109], [0, 0, 0, 87, 0, 0, 36, 139, 112, 0, 240, 223, 0, 41, 0, 126, 82, 0, 0, 93, 0, 242, 0, 0, 114, 0, 41, 116, 153, 0, 36, 0, 0, 153, 36, 0, 0, 41, 0, 116, 0, 0, 0, 107], [0, 0, 0, 0, 46, 46, 0, 117], [244, 0, 229, 229, 0, 248, 41, 0, 98, 0], [150, 228, 228, 65, 0, 0, 82, 141, 93, 57, 228, 228, 36, 52], [150, 150, 228, 60, 0, 93, 41, 130, 111, 89, 0, 89, 24, 125], [0, 46, 117, 77, 0, 0, 0, 0, 126, 0, 0, 52, 0, 0, 0, 36]]}\n"
     ]
    }
   ],
   "source": [
    "vector_dict = {}\n",
    "for key, value in question_mapping.items():\n",
    "    vector_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        vector_dict[key][student] = []\n",
    "        for sent in answer:\n",
    "            words = sent.split(' ')\n",
    "            temp_list = []\n",
    "            for w in words:\n",
    "                for cluster_key, cluster_value in clust_dict.items():\n",
    "                    if w in clust_dict[cluster_key]:\n",
    "                        temp_list.append( cluster_key)\n",
    "            vector_dict[key][student].append(temp_list)\n",
    "            \n",
    "for k, v in vector_dict.items():\n",
    "    print(k, '    ', v)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_name = {}\n",
    "rep = 0\n",
    "for key, value in vector_dict.items():\n",
    "    for student, vector in value.items():\n",
    "        for v in vector:\n",
    "            vector_name[tuple(v)] = rep\n",
    "            rep+=1\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskc      {'g0pC': [0, 1, 2, 3, 4, 5, 6, 7, 8], 'g0pE': [9], 'g1pA': [10, 11, 12, 76, 14, 15, 16, 17, 18, 19, 20], 'g3pB': [21, 22, 23, 24, 25, 26, 27, 28, 29], 'g0pB': [30, 74, 153, 108, 137, 78, 133, 134, 82, 39, 40, 138, 42], 'g2pA': [43, 153, 45, 46, 47, 48, 49, 50, 51, 133, 53, 82, 55, 56, 57, 86, 909, 60], 'g0pD': [61, 62, 63, 64, 65, 66, 67, 68, 137, 70, 71], 'orig': [72, 153, 74, 155, 76, 137, 78, 79, 133, 134, 82, 83, 84, 85, 86, 909, 118], 'g3pC': [89, 90, 91, 92, 93, 94, 95], 'g2pB': [96, 97, 98, 99, 100, 101, 102, 103, 104, 105], 'g0pA': [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118], 'g4pC': [119, 120, 909, 122, 909, 124, 750, 909, 127, 909, 129, 909, 131, 132], 'g4pE': [133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143], 'g2pC': [144, 145, 146, 147, 148, 149, 150, 151], 'g4pB': [152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163], 'g1pD': [164, 165, 166, 167], 'g4pD': [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'g2pE': [184, 185, 186, 187, 188], 'g3pA': [189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'g1pB': [202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217]}\n",
      "taskd      {'g0pE': [218, 219, 220], 'g3pB': [221, 222, 223, 224, 225, 226], 'g1pA': [227, 228, 229, 372, 231, 232, 233], 'g0pC': [367, 235, 236, 237, 370, 239, 240, 241], 'g0pD': [242, 243], 'g3pC': [244, 245, 246, 247, 248], 'orig': [367, 392, 333, 369, 253, 371, 372, 373, 374, 375, 316, 386, 318, 386, 320, 378], 'g2pA': [367, 392, 333, 369, 370, 371, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284], 'g0pB': [360, 286, 287, 288, 386, 290, 291, 292, 293, 294, 295, 296], 'g4pE': [297, 298, 909, 300, 301, 302, 303, 304, 305], 'g4pC': [391, 307, 308, 369, 370, 371, 373, 313, 314, 315, 316, 386, 318, 386, 320, 378], 'g0pA': [322, 323, 324, 325, 326, 327, 328, 329, 330], 'g2pB': [331, 332, 333, 334, 335, 336, 337, 338, 373, 340, 341, 342, 343], 'g2pE': [344, 345, 346, 347, 348, 354], 'g4pD': [350, 351, 352, 353, 354, 355, 356, 357, 358, 359], 'g1pB': [360, 361, 362, 363, 364, 365, 366], 'g3pA': [367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378], 'g4pB': [379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390], 'g2pC': [391, 392, 393, 394, 395, 396, 397, 398, 399], 'g1pD': [400, 401, 402, 403, 404, 405, 406]}\n",
      "taske      {'g0pE': [407, 528, 622, 602, 603, 623], 'g1pA': [413, 414, 415, 416, 417, 418, 419, 420, 421, 422], 'g3pB': [423, 424, 622, 426, 603, 428, 632, 624], 'g0pC': [431, 432, 433, 599, 559, 436, 437, 438, 439, 440], 'g0pD': [441, 442, 443, 444, 445], 'orig': [446, 528, 598, 599, 559, 600, 622, 602, 603, 623, 624, 457, 625, 626, 909, 628, 909, 630, 631, 909, 466, 467, 632, 633, 634, 635, 636, 637, 474, 638, 639], 'g3pC': [477, 478, 479, 480, 481, 482], 'g0pB': [483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 909, 494, 909, 496, 497], 'g2pA': [498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513], 'g4pE': [514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 909, 525, 526], 'g2pB': [621, 528, 529, 530, 602, 603, 623, 624, 535, 536, 628, 630, 631], 'g0pA': [540, 541, 542, 543, 544, 909, 546, 909, 548, 909, 550, 551, 552, 553, 554], 'g4pC': [555, 556, 557, 599, 559, 560, 561, 562, 563, 624, 565, 566, 567], 'g4pD': [568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 634, 579], 'g2pE': [580, 581, 582, 583, 584, 585, 586, 587], 'g3pA': [588, 589, 590, 591, 592, 593, 594, 595, 596], 'g1pB': [597, 598, 599, 600, 622, 602, 603, 623, 605, 606, 607, 608, 609, 610], 'g2pC': [611, 612, 613, 614, 615, 616, 617, 618, 619, 620], 'g4pB': [621, 622, 623, 624, 625, 626, 909, 628, 909, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], 'g1pD': [641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651]}\n",
      "taskb      {'g0pC': [652, 653, 654, 655, 656, 657, 658, 659, 660], 'g0pE': [802, 753, 663], 'g3pB': [664, 665, 666, 667, 668, 669, 670, 671, 672, 673], 'g1pA': [674, 675, 676, 677, 678, 679, 680, 681, 682], 'g2pA': [683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694], 'g0pB': [695, 696, 697, 698, 699, 700, 701], 'g0pD': [702, 703, 704, 705], 'g3pC': [706, 707, 708, 709, 710, 711, 712], 'orig': [802, 753, 775, 776, 777, 778, 719, 720, 721, 722, 723, 779, 780, 781, 727, 728, 803, 804, 731, 756, 757, 734, 782, 783, 737], 'g4pC': [738, 739, 740, 741, 742, 743, 744], 'g0pA': [802, 746, 747, 750, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759], 'g2pB': [760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770], 'g4pE': [771, 772, 773, 776, 775, 776, 777, 778, 779, 780, 781, 782, 783], 'g4pB': [784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794], 'g2pC': [795, 796, 797, 798, 799, 800, 801], 'g1pD': [802, 803, 804, 820, 806, 822, 808, 824, 826, 827, 812, 813], 'g2pE': [814, 815, 816, 817, 818, 819], 'g4pD': [820, 909, 822, 823, 824, 909, 826, 827, 828, 829, 830, 831, 832, 833], 'g1pB': [834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844], 'g3pA': [845, 846, 847, 848, 849, 850, 851, 852, 853]}\n",
      "taska      {'g0pC': [854, 855, 856, 857, 858, 859, 860, 861, 862, 863], 'g3pB': [864, 865, 866, 867, 868, 869, 870, 871, 872, 873], 'g1pA': [874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885], 'g0pE': [954, 933, 888, 1030, 936, 937, 959, 960, 961, 962, 1031, 1032, 1033], 'g2pA': [899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913], 'g0pB': [914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925], 'g3pC': [954, 959, 960, 961, 930, 1033], 'orig': [954, 933, 1029, 1030, 936, 937, 959, 960, 961, 962, 1031, 1032, 1033, 966], 'g0pD': [946, 947, 948, 949, 950, 961, 952, 1031], 'g4pC': [954, 955, 956, 1029, 1030, 959, 960, 961, 962, 1031, 1032, 1033, 966], 'g0pA': [967, 968, 969, 970, 971, 972, 973, 974], 'g2pB': [975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987], 'g4pE': [988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998], 'g1pD': [999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009], 'g4pB': [1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027], 'g2pC': [1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037], 'g1pB': [1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], 'g3pA': [1049, 1050, 1051, 1052, 1053, 1054, 1055], 'g2pE': [1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068], 'g4pD': [1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079]}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "pro_dict = {}\n",
    "for key, value in vector_dict.items():\n",
    "    pro_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        pro_dict[key][student] = []\n",
    "        for v in answer:\n",
    "            ans = tuple(v)\n",
    "            pro_dict[key][student].append(vector_name[ans])\n",
    "\n",
    "for key, value in pro_dict.items():\n",
    "    print(key, '    ', value)\n",
    "    break\n",
    "    \n",
    "print(len(pro_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyfpgrowth\n",
    "transactions = []\n",
    "inp = \"taske\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[407, 528, 622, 602, 603, 623], [413, 414, 415, 416, 417, 418, 419, 420, 421, 422], [423, 424, 622, 426, 603, 428, 632, 624], [431, 432, 433, 599, 559, 436, 437, 438, 439, 440], [441, 442, 443, 444, 445], [446, 528, 598, 599, 559, 600, 622, 602, 603, 623, 624, 457, 625, 626, 909, 628, 909, 630, 631, 909, 466, 467, 632, 633, 634, 635, 636, 637, 474, 638, 639], [477, 478, 479, 480, 481, 482], [483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 909, 494, 909, 496, 497], [498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513], [514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 909, 525, 526], [621, 528, 529, 530, 602, 603, 623, 624, 535, 536, 628, 630, 631], [540, 541, 542, 543, 544, 909, 546, 909, 548, 909, 550, 551, 552, 553, 554], [555, 556, 557, 599, 559, 560, 561, 562, 563, 624, 565, 566, 567], [568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 634, 579], [580, 581, 582, 583, 584, 585, 586, 587], [588, 589, 590, 591, 592, 593, 594, 595, 596], [597, 598, 599, 600, 622, 602, 603, 623, 605, 606, 607, 608, 609, 610], [611, 612, 613, 614, 615, 616, 617, 618, 619, 620], [621, 622, 623, 624, 625, 626, 909, 628, 909, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], [641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651]]\n"
     ]
    }
   ],
   "source": [
    "for k, v in pro_dict.items():\n",
    "    if k == inp:\n",
    "        for name, vec in v.items():\n",
    "            transactions.append(vec)\n",
    "print(transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[528, 602, 623], [528, 602, 603], [528, 602, 909], [528, 603, 623], [528, 623, 909]]\n"
     ]
    }
   ],
   "source": [
    "patterns = pyfpgrowth.find_frequent_patterns(transactions, 3)\n",
    "frequent_list = []\n",
    "for p in patterns:\n",
    "    if len(p) < 3:\n",
    "        continue\n",
    "    else:\n",
    "        frequent_list.append(list(p))\n",
    "print(frequent_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_sub(sub, lst):\n",
    "    ln = len(sub)\n",
    "    for i in range(len(lst) - ln + 1):\n",
    "        if all(sub[j] == lst[i+j] for j in range(ln)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied students for  taske   {'g0pE', 'g2pB', 'orig', 'g1pB'}\n",
      "Copied students for  taska   {'g0pE', 'orig', 'g2pC', 'g3pC', 'g4pC'}\n",
      "Copied students for  taskd   {'orig', 'g2pA', 'g4pC', 'g3pA'}\n"
     ]
    }
   ],
   "source": [
    "output_dict= {}\n",
    "for lst in frequent_list:\n",
    "    for k, v in pro_dict.items():\n",
    "        for name, vec in v.items():\n",
    "            if is_sub(lst,vec):\n",
    "                if k not in output_dict:\n",
    "                    output_dict[k] = [name]\n",
    "                else:\n",
    "                    output_dict[k].append(name)\n",
    "\n",
    "# print(output_dict)\n",
    "for k, v in output_dict.items():\n",
    "    print('Copied students for ', k, ' ', set(v))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xl = pd.ExcelFile(\"corpus_final.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = xl.parse(\"File list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = df[['File','Category']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is :  0.7222222222222222\n",
      "Recall is :  0.0693950177935943\n",
      "Accuracy is :  0.6322624743677375\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "fp = 0\n",
    "for key, value in output_dict.items():\n",
    "    for v in value:\n",
    "        ans = v+key+'.txt'\n",
    "        head = key\n",
    "        for index, row in c.iterrows():\n",
    "            if row['File'].split('_')[1].split('.')[0] == head:\n",
    "                if row['File'].split('_')[0] == v:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        tp+=1\n",
    "                    else:\n",
    "                        fp+=1\n",
    "                else:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        fn +=1\n",
    "                    else:\n",
    "                        tn+=1\n",
    "\n",
    "precision = float(tp/(tp+fp))                        \n",
    "print('Precision is : ', precision)\n",
    "recall = float(tp/(tp+fn))\n",
    "print('Recall is : ', recall)\n",
    "print('Accuracy is : ', (tp+tn)/(tp+fn+tn+fp))\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
