{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.cluster import KMeans\n",
    "from numbers import Number\n",
    "from pandas import DataFrame\n",
    "import sys, codecs, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autovivify_list(dict):\n",
    "  def __missing__(self, key):\n",
    "    '''Given a missing key, set initial value to an empty list'''\n",
    "    value = self[key] = []\n",
    "    return value\n",
    "\n",
    "  def __add__(self, x):\n",
    "    '''Override addition for numeric types when self is empty'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return x\n",
    "    raise ValueError\n",
    "\n",
    "  def __sub__(self, x):\n",
    "    '''Also provide subtraction method'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return -1 * x\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_word_vector_matrix(vector_file, n_words):\n",
    "  '''Return the vectors and labels for the first n_words in vector file'''\n",
    "  numpy_arrays = []\n",
    "  labels_array = []\n",
    "  with codecs.open(vector_file, 'r', 'utf-8') as f:\n",
    "    for c, r in enumerate(f):\n",
    "      sr = r.split()\n",
    "      labels_array.append(sr[0])\n",
    "      numpy_arrays.append( numpy.array([float(i) for i in sr[1:]]) )\n",
    "\n",
    "      if c == n_words:\n",
    "        return numpy.array( numpy_arrays ), labels_array\n",
    "\n",
    "  return numpy.array( numpy_arrays ), labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_word_clusters(labels_array, cluster_labels):\n",
    "  '''Return the set of words in each cluster'''\n",
    "  cluster_to_words = autovivify_list()\n",
    "  for c, i in enumerate(cluster_labels):\n",
    "    cluster_to_words[ i ].append( labels_array[c] )\n",
    "  return cluster_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=126, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector_file = 'vectors.txt' \n",
    "n_words = int(1262) # Number of words to analyze \n",
    "reduction_factor = float(0.1) # Amount of dimension reduction {0,1}\n",
    "n_clusters = int( n_words * reduction_factor ) # Number of clusters to make\n",
    "df, labels_array = build_word_vector_matrix(input_vector_file, n_words)\n",
    "kmeans_model = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans_model.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_labels  = kmeans_model.labels_\n",
    "cluster_inertia   = kmeans_model.inertia_\n",
    "cluster_to_words  = find_word_clusters(labels_array, cluster_labels)\n",
    "\n",
    "clusters = []\n",
    "for c in cluster_to_words:\n",
    "    clusters.append(cluster_to_words[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ['the', 'of', 'is', 'to', 'and', 'in', 'that', 'as', 'it', 'by', 'are', 'used', 'an', 'vector', 'term', 'has', 'one', 'also', 'new', 'at']\n",
      "5      ['05', '06', '000464908', '000750848', '00152028', '41461e', '69545e', '07']\n",
      "8      ['be', 'can']\n",
      "13      ['for', 'example']\n",
      "14      ['this', 'using', 'so', 'would', 'calculated', 'computed', 'say', 'exhibit']\n",
      "15      ['or', 'ancestor', 'exposed', 'those', 'adding']\n",
      "16      ['probability', 'theory', 'prior']\n",
      "17      ['programming', 'dynamic', 'computer', 'science']\n",
      "19      ['which', 'inheritance', 'way', 'form']\n",
      "22      ['pagerank', 'on', 'page', 'links', 'other', 'pages', 'web']\n",
      "24      ['from', 'all', 'common']\n",
      "25      ['classes', 'derived', 'base', 'referred']\n",
      "26      ['h0k', 'he', 'ubx', 'hhk', 'hij', 'hijses']\n",
      "28      ['theorem', 'bayes', 'given', 'often']\n",
      "29      ['with', 'code', 'set', 'existing', 'similar']\n",
      "30      ['have', 'been']\n",
      "31      ['document', 'each', 'between', 'query']\n",
      "33      ['problems', 'sub', 'into']\n",
      "34      ['documents', 'known', 'such', 'vectors', 'represented', 'same', 'well']\n",
      "35      ['optimal', 'subproblems', 'problem', 'solutions', 'substructure', 'overlapping']\n",
      "36      ['information', 'retrieval']\n",
      "37      ['probabilities', 'events', 'two', 'random']\n",
      "38      ['space', 'model']\n",
      "39      ['google', 'algorithm', 'link', 'analysis']\n",
      "41      ['class', 'another', 'best', 'superclass', 'only', 'subclass', 'child', 'decisions', 'parent']\n",
      "42      ['number', 'value', 'its', 'importance', 'based', 'depends', 'like', 'original', 'within', 'name', 'cosine', 'dimensionality', 'webpage']\n",
      "43      ['terms', 'words', 'if']\n",
      "44      ['called', 'sometimes']\n",
      "45      ['we', 'not', 'then', 'they']\n",
      "46      ['these', 'objects', 'both']\n",
      "47      ['conditional', 'marginal', 'relates']\n",
      "48      ['more', 'methods']\n",
      "50      ['may', 'solution', 'find', 'when', 'solve', 'could', 'need', 'you', 'observed', 'overall', 'applied']\n",
      "51      ['where', 'about', '000121931', '000154344', '000597976', '00132224', '0014425', '00163446']\n",
      "52      ['any', 'fruit', 'generalization', 'instance', 'hierarchy', 'represent', 'element', 'support', 'representation', 'exhibition', 'observations', 'produced', 'technique']\n",
      "53      ['object', 'oriented']\n",
      "54      ['many', 'will', 'there', 'how', 'their', 'process', 'important', 'results', 'uses', 'high', 'linked', 'rank', 'sites', 'determine']\n",
      "55      ['means', 'plan', 'action', 'finding', 'sense', 'acceptable']\n",
      "57      ['method', 'solving', 'optimization']\n",
      "58      ['search', 'internet', 'engine']\n",
      "59      ['was', 'first', 'use', 'some', 'order', 'ways', 'general', 'keyword', 'vocabulary', 'concept', 'occurs', 'graph', 'valid', 'equal', 'originally', 'appear', 'invented', 'lost']\n",
      "60      ['8i', '8w', 'time', '8e', '8j', 'b8', 'c8', 'h8', '8l', '8p', 'd8', 'r8', 't8', '8n', 'a8', 'f8', 'x8', 'k8', '7o', '7p', '87', 'v8', '79', '84', '7v', '97', 'j8', 'v9', 'w7', '28', '78', '7a', '7q', '7r', '8r', '58', '7f', '7y', '7z', '8c', '9s', 'v7', '18', '7c', '7h', '7k', '9r', 'e8', 'f7', 'g9', 'y7', '7b', '7g', '7i', '86', '9a', 'collection', 'every', 'i7', 'main', '09', '19', '6m', '7e', '7s', '7x', '83', '_8', 'formula', 'r9', '10', '77', '7m', '90', 'available', 'c7', 'g7', 'h7', 'key', 'see', 'u7', 'z7', 'zs', '59', '6b', '6v', '72', '7_', '7l', '7n', '91', 'b7', 'e7', 'factor', 'following', 'k7', 'n7', 'om', 'possible', 'relevance', 'w9', '6e', '73', '76', '8_', '96', 'ae', 'appears', 'assumptions', 'basically', 'dx', 'fs', 'ht', 'idea', 'lg', 'md', 'memoization', 'popular', 'ra', 'rd', 'research', 'rj', 'ss', 'subsets', 'zn', '17', '37', '4e', '5x', '67', '6i', '6l', '6r', '70', '74', '93', '_9', 'ac', 'accurate', 'bd', 'bm', 'chance', 'd6', 'd7', 'dc', 'es', 'evidence', 'fi', 'fj', 'formed', 'fv', 'g6', 'gr', 'h1', 'hc', 'ii', 'il', 'inherited', 'io', 'iv', 'j6', 'kf', 'km', 'kx', 'lt', 'measure', 'normally', 'occurrence', 'og', 'previous', 'proportions', 'qf', 'qj', 'remembered', 'ri', 'together', 'un', 'vl', 'wa', 'wz', 'xl', 'xt', 'ya']\n",
      "61      ['different', 'non', 'zero', 'several', 'identifiers', 'frequency', 'index', 'container', 'fleshy', 'seed', 'shares', 'vanishing']\n",
      "62      ['8x', '8v', '8z', '8b', 'l8', 'p8', '8m', 's8', '9t', 'i8', '8k', '8o', '8t', '9m', 'g8', '88', '8a', '9g', '9h', 'm8', '89', 'n8', 'u8', '9i', '9y', '9q', '9b', 'c9', 'since', 'u9', 'x9', 'q9', 'r7', '9d', '9o', 'p9', '68', '81', '95', 'a9', 'describe', '29', '49', '85', 'dp', 'e9', 'l9', 'y9', 'd9', 'f9', 'ir', 'l7', '9_', 'frequencies', 'i9', 'k9', 'm7', 'm9', 'q7', '08', '69', 'a1', 'a7', 'modules', 'pr', 's9', 'z9', 'ff', 'hence', 'polymorphism', 'queries', 'systems', 'uh', 'whilst', 'xp', 'bw', 'calculating', 'equation', 'field', 'hg', 'kw', 'ny', 'postgraduate', 'qw', 'ro', 'transport', 'very', 'who', 'whole', 'yz', 'z6', 'animals', 'ch', 'content', 'da', 'debates', 'eh', 'features', 'fk', 'four', 'functions', 'further', 'gb', 'greater', 'h6', 'just', 'jz', 'ku', 'language', 'make', 'modification', 'mt', 'nodes', 'pp', 'public', 'qz', 'recursively', 'surfer', 'type', 'ui', 'uq', 'without', 'yr', 'zp', '<unk>']\n",
      "63      ['up', 'but', 'approach', 'assigns', 'describes', 'needs', 'others', 'do', 'extend', 'larger', 'needed', 'patient', 're', 'symptoms', 'won', 'even', 'intended', 'made', 'out', 'relation', 'save', 'stored', 'cannot', 'consider', 'create', 'due', 'found', 'group', 'solves', 'try', 'access', 'add', 'again', 'cases', 'manipulation', 'said']\n",
      "64      ['values', 'already', 'defined', 'weights', 'developed']\n",
      "65      ['8q', 'o8', 'being', '8h', 'most', '98', 'properties', '8d', '8f', '8u', '8g', 'y8', 'q8', 'w8', 'z8', '7w', 'structure', '48', 'therefore', '38', '7d', '8s', 'b9', 'kind', 'models', 'usually', '7u', 'allows', 'provides', 'relationship', 'system', 'useful', 'what', '7t', 'advantage', 'j7', '82', 'generally', 'ja', 'n9', '6a', 'considered', 'jj', 'second', 'vote', 'populations', 'seen', 'acts', 'cx', 'df', 'fu', 'jm', 'qd']\n",
      "66      ['student', 'however', 'because', 'program', 'event', 'diagnosis', 'distribution', 'does', 'correct', 'proposed', 'formal', 'right']\n",
      "67      ['no', 'particular', 'connection']\n",
      "68      ['word', 'mathematical', 'instead', 'languages', 'categorization', 'basic', 'thus', 'synonym', 'recursive']\n",
      "69      ['9j', '9x', '8y', '9n', '9p', '9f', '9w', '9l', '9v', 'h9', '9k', '80', '99', 'o9', '9z', '2099e', '9u', 'j9', '9c', 't9', '92', 'apples', 'much', 'step', 'takes', '39', 'down', 'three', '75', 'top', 'de', 'disagree', 'interfaces', 'sufficiently', 'circle', 'view', 'ba', 'below', 'context', 'conversely', 'matches', 'numeric', 'precisely', 'wear', 'yn', '60', 'co', 'described', 'dual', 'entity', 'f1', 'fd', 'nq', 'patented', 'qs', 'reach', 'shape', 'st', 'superclasses', 'weightingthe']\n",
      "70      ['compute', 'certain', 'posterior', 'calculate']\n",
      "71      ['inherit', 'attributes', 'solved', 'variables', 'divided', 'beliefs', 'data', 'subclasses', 'themselves', 'updated', 'behavior', 'chosen', 'behaviours', 'instances']\n",
      "72      ['9e', '000226815', 'apple', 'interpretations', 'share', 'frequentist', 'orange', 'etc', 'entities', 'statistics', 'hyperlinked', 'lot', 'bayesians', 'degrees', 'schedule', 'unique', 'finalized', 'processing', 'types', 'abstraction', 'mechanism', 'uncertainty', 'angles', 'happening', 'long', 'pieces']\n",
      "73      ['computing', 'similarity', 'f2', 'take', 'f3', 'account', 'f4', 'product', 'train', 'large', 'poor', 'poorly', 'involves', 'pre', 'reciprocal', 'small', 'smaller', 'car', 'engineering', 'mango', 'quotations']\n",
      "74      ['bayesian', 'world', 'wide', 'relative', 'application', 'around', 'debate', 'definition', 'similarities', 'upon', 'complexity', 'scale', 'students', 'angle', 'measuring', 'reducing', 'foundations', 'purpose', 'specified', 'total', 'distinct', 'givenis', 'occurring']\n",
      "75      ['keywords', 'single', 'longer', 'phrases']\n",
      "76      ['000222005', '00028579', '000606723', '000641574', '00127091', '00145284']\n",
      "77      ['000714138', '00100001', '00112502', '00116851', '00122709', '00139828', '00160493', '00166282']\n",
      "78      ['000837489', '00024084', '000253858', '000306806', '00076664', '00078398', '00154063']\n",
      "79      ['00105573', '000218071', '000346468', '000722866', '00118384', '00122644', '00145348', '98124e']\n",
      "80      ['00127245', '00027091', '000344981', '000641772', '00127034']\n",
      "81      ['false', 'result', 'match', 'role', 'applications', 'negative', 'positive', 'might', 'associated', 'frequentists', 'substrings']\n",
      "82      ['specific', 'dimension', 'separate', 'corresponds']\n",
      "83      ['than', 'bellman', 'either', 'them', 'typically', 'little', 'accomplished', 'control', 'dividing', 'having', 'over', 'overriding', 'prob', '1940s', 'engines', 'learning', 'richard', 'shared', 'controlled', 'human', 'replacing', '1953', 'comparing', 'specialised']\n",
      "84      ['weighting', 'path', 'site', 'patent', 'ranking', 'higher', 'actual', 'characteristics', 'your', 'algorithms', 'factors', 'meaning', 'subproblem', 'clicking', 'goal', 'person', 'users', 'visits', 'denotes', 'inbound', 'include', 'randomly', 'relevant', 'toolbar', 'among', 'outbound', 'website', 'affect', 'articles', 'counts', 'influence', 'modern', 'provided', 'through']\n",
      "85      ['000104496', '000349485', '00134634', '0015882', '0015892']\n",
      "86      ['000112297', '000510361', '000822361', '000851915', '000970411', '00112897']\n",
      "87      ['000118776', '000154858', '0002997', '000379887', '000740185', '000767073', '00122127', '00144738', '00158507']\n",
      "88      ['000121415', '000251048', '000289281', '00029439', '000388454', '000419433', '000741238', '00110349', '00121285', '00127489']\n",
      "89      ['000128402', '000466403', '000935097', '00118882', '00127242']\n",
      "90      ['000146166', '000228113', '000373652', '00038978', '000392118', '00160403']\n",
      "91      ['000149611', '000254484', '000342545', '000438051', '000481291', '000486314', '000717298', '000782035', '000908618', '000918943', '00103384', '00107373', '00120731', '00121033', '00134052', '00135353', '00148223', '00148554', '0015764', '00159165', '0669e', '28277e', '74935e', '77299e', '7908e', '79304e', '000295394']\n",
      "92      ['000173975', '000281587', '000434826', '000828879', '000997342', '00134573', '00138859', '00147126', '00149773']\n",
      "93      ['000176249', '000664931', '00067521', '000923061', '00104599', '0011547', '00150916']\n",
      "94      ['000204662', '000233989', '000454297', '000615239', '00132652', '00162791']\n",
      "95      ['000208043', '00028446', '000388528', '000543594', '000784815', '000914112', '000943677', '000972417', '0009751', '00130591', '00154554', '00158112', '63164e']\n",
      "96      ['000209893', '000468307', '000606068', '000658771', '000927189', '000997195', '00123337', '00146592', '00159539']\n",
      "97      ['000213784', '00044146', '000679629', '00102065', '00130641', '00132182', '00133258']\n",
      "98      ['000218611', '000627347', '000654478', '000818812', '00147324']\n",
      "99      ['000228605', '000233216', '000247751', '000302909', '000507011', '000510669', '000672392']\n",
      "100      ['000230336', '000257429', '000309389', '000404928', '000658096', '000873691', '00111769', '00143611', '00156054']\n",
      "101      ['000237438', '000393385', '000533912', '000661417', '000699741', '00121509']\n",
      "102      ['000253155', '000558035', '00060477', '00143099']\n",
      "103      ['000253817', '000354644', '000479967', '00160269']\n",
      "104      ['000288034', '000509222', '000566388', '000727566', '00095051', '00117286', '00143176', '0016061']\n",
      "105      ['000288376', '000592722', '00109647', '00159964', '00165102']\n",
      "106      ['000339263', '00062685', '000967188', '00104602', '00148124']\n",
      "107      ['000385199', '0010244', '00116003', '00125393']\n",
      "108      ['000392922', '000429939', '000679533', '000689932', '000692842', '000723977', '000797545', '000863904', '00116315', '00124763', '00126601', '00133235', '00153604', '00153979', '0016119', '00162254']\n",
      "109      ['000407494', '000624961', '00075486', '000948308', '000993489', '00104788', '00106799', '00124217', '00147916', '00150931', '0015844']\n",
      "110      ['000437583', '00106998', '00112648', '001343']\n",
      "111      ['00046674', '000766635', '00118601', '00162762']\n",
      "112      ['000515494', '000681381', '000920251', '000978992', '00142694']\n",
      "113      ['000521099', '00101139', '00113677', '00120606', '00129875']\n",
      "114      ['00053947', '000884418', '000894328', '00125502', '00146811', '00153857']\n",
      "115      ['000555889', '000568793', '000965391', '00123691']\n",
      "116      ['000599943', '000788925', '000798503', '000861262', '00109457', '00159783', '0122e', '1804e']\n",
      "117      ['00070198', '000721091', '00105603', '00122734']\n",
      "118      ['000769519', '000820195', '000955627', '00149124']\n",
      "119      ['00110873', '00137624', '00141866', '00142988', '00159927']\n",
      "120      ['after', 'thomas', 'law', 'rev']\n",
      "121      ['less', 'indexing', 'rankings', 'relevancy', 'filtering', 'cognitive', 'smart', 'mathematics']\n",
      "122      ['assigned', 'should', 'according', 'assign']\n",
      "123      ['trousers', 'tf', 'central', 'idf', 'plays', 'simple', 'case', 'powerful', 'relationships', 'schemes', 'topic', 'constant', 'girl', 'popularity', 'wearing', 'yo', 'computation', 'design', 'expressed', 'discuss', 'happened', 'solvable', 'systemdocument', 'theoretical', 'true']\n",
      "124      ['naive', 'reuse', 'x7', 'bottom', 'numerical', '7j', 'hijubx', 'university', 'until', 'comes', 'help', 'must', 'rq', 'shortest', 'stanford', 'f5', 'had', 'naturally', 'qx', 'economy', 'our', 'references', 'rh', 'ru', '1g', 'get', 'gi', 'qu', 'refined', 'rz', 'sn', 'storing', 'us', 'weight']\n",
      "125      ['representing', 'text', 'algebraic']\n"
     ]
    }
   ],
   "source": [
    "clust_dict = {}\n",
    "for clus in clusters:\n",
    "    if len(clus) == 1:\n",
    "        if 0 not in clust_dict:\n",
    "            clust_dict[0] = clus\n",
    "        else:\n",
    "            clust_dict[0] += clus\n",
    "    else:\n",
    "        clust_dict[clusters.index(clus)] = clus\n",
    "for key, value in clust_dict.items():\n",
    "    print(key, '    ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, nltk, re\n",
    "\n",
    "# Open a file\n",
    "path = \"DATA-NLP\"\n",
    "dirs = os.listdir( path )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_mapping = dict() # Mapping to question dictionary\n",
    " # Mapping to student as key and answer as value\n",
    "\n",
    "for file in dirs:\n",
    "    if file == '.DS_Store':\n",
    "            continue\n",
    "    path_to_file=path+'/'\n",
    "    file_name = file\n",
    "    split_name = file.split('_')\n",
    "    student_name = split_name[0]\n",
    "    question_number = split_name[1].split('.')[0]\n",
    "    if question_number not in question_mapping:\n",
    "        question_mapping[question_number] = {}\n",
    "    path_to_file += file_name\n",
    "    with open(path_to_file, 'r', encoding = 'latin1') as f:\n",
    "        mylist = f.read()\n",
    "        sent_tokenize_list = nltk.sent_tokenize(mylist)\n",
    "        temp = []\n",
    "        for i in sent_tokenize_list:\n",
    "            sent = i.lower()\n",
    "            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "            temp.append(sent)\n",
    "        question_mapping[question_number][student_name] = temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskc      {'g0pC': [[0, 0, 38, 38, 0, 51, 31, 31, 0, 0, 0, 43, 51, 54, 59, 0, 83], [31, 31, 0, 0, 51, 31, 68, 0, 82], [0, 0, 0, 45, 0, 0, 61, 0, 68, 82], [0, 0, 14, 63, 0, 0, 0, 0, 0, 31, 0, 0, 22, 0, 0, 0, 13, 14, 50, 8, 0, 42, 73, 31, 84, 37, 34], [14, 54, 50, 0, 31, 0, 37, 34, 0, 73, 0, 0, 83], [0, 31, 0, 58, 38, 0, 31, 8, 0, 8, 34, 0, 0, 45, 50, 50, 0, 31, 0, 0, 0, 42, 74, 0, 84, 31], [54, 0, 42, 0, 19, 8, 8, 0, 0, 0, 0], [54, 0, 59, 29, 14, 63, 73, 0, 42, 74, 31, 31, 0, 8, 8, 0, 0, 42, 0, 8, 8, 0, 0, 0, 14, 35, 50, 8, 59, 0, 45, 0, 22, 14], [0, 69]], 'g0pE': [[0, 52, 0, 29, 0, 34, 0, 34, 0, 24, 0, 38, 0, 34, 0, 0, 0, 38, 0, 38, 38, 0, 0, 0, 0, 36, 36, 62, 34, 22, 31, 31, 0, 31, 45, 59, 0, 68, 0, 38, 69, 0, 14, 0, 0, 69, 0, 62, 0, 34, 0, 0, 34, 0, 38, 0, 0, 31, 60]], 'g1pA': [[0, 0, 38, 38, 0, 0, 125, 38, 0, 0, 52, 125, 34, 0, 52, 46, 65, 0, 34, 0, 61, 13, 52, 61, 43], [42, 81, 84, 36, 121, 36, 36, 121, 0, 121, 121], [29, 0, 14, 38, 34, 0, 34, 0, 34], [31, 82, 82, 0, 82, 0], [0, 42, 0, 0, 0, 61, 61, 43, 0, 59, 0, 0, 31], [61, 61, 59, 30, 30, 64, 0, 62, 46, 64, 0, 34, 0, 0, 64], [0, 0, 0, 41, 34, 123, 0, 123, 123, 0, 61, 31, 61, 84], [0, 38, 8, 8, 0, 0, 54, 0, 121, 121, 0, 34, 0, 59, 58, 14, 0, 60, 0, 31, 74, 16, 0, 83, 0, 42, 31, 0, 51, 0, 31, 0, 34, 0, 34, 65, 0, 0, 0, 0, 34, 0, 0, 0, 72, 31, 31, 31, 0], [0, 0, 38, 38, 59, 0, 0, 0, 0, 34, 0, 0, 61, 31, 61, 38], [0, 14, 38, 0, 0, 82, 64, 0, 0, 31, 34, 0, 0, 0], [0, 0, 38, 0, 0, 82, 64, 0, 62, 0, 84, 0, 0, 0, 65, 63, 45, 84, 0]], 'g3pB': [[54, 0, 73, 42, 0, 65, 0, 0, 57, 0, 35, 0, 36, 36, 0, 45, 0, 24, 42, 22, 0, 0, 69, 68, 29, 16, 0], [0, 0, 38, 38, 0, 0, 0, 46, 48, 0, 0, 0, 0, 125, 38], [0, 0, 0, 38, 38, 31, 0, 34, 0, 0], [42, 14, 0, 31, 82, 82, 0, 82, 0, 51, 0, 0, 83, 75, 68, 59, 15], [43, 0, 0, 42, 0, 31, 0, 42, 0, 0, 0, 0, 61], [43, 0, 59, 0, 0, 31, 42, 42, 0, 61, 61], [0, 70, 54, 84, 31, 31, 0, 0, 59, 58, 0, 42, 42, 0, 0, 74, 31, 0, 34, 0, 0, 70, 68, 0, 0, 84, 74], [0, 0, 38, 38, 66, 0, 45, 62, 42, 45, 30, 73, 73, 64, 72, 34, 0, 73, 34, 0, 59, 0, 43, 66, 45, 81, 81, 69, 50, 8, 51, 0, 43, 42, 43, 71, 0, 34, 0, 122, 81, 63, 59, 61, 50, 81, 81, 69], [54, 0, 42, 0, 22, 65, 0, 0, 42, 22, 15, 63, 0, 0, 38, 38, 0, 46, 0, 0, 63, 0, 46, 33]], 'g0pB': [[0, 38, 38, 0, 0, 125, 38, 13, 125, 125, 34, 0, 0, 59, 52, 46, 0, 34, 0, 61, 34, 0, 13, 13, 61, 43], [42, 59, 59, 59, 0, 0, 121, 36, 36, 65], [0, 0, 0, 0, 36, 121, 36, 36, 121, 0, 121, 121], [31, 0, 34, 0, 0, 0, 31, 82, 82, 0, 82, 0], [43, 0, 59, 0, 0, 31, 42, 42, 0, 0, 0, 0, 61, 61], [61, 61, 59, 0, 73, 46, 64, 0, 34, 0, 0, 64, 30, 30, 64], [0, 74, 0, 0, 42, 22, 0, 74], [83, 43, 0, 75, 43, 75, 15, 75, 75], [43, 0, 43, 0, 71, 0, 8, 0, 43, 0, 42, 0, 0, 0, 0, 0, 42, 0, 43, 0, 0, 59, 0, 42, 0, 74, 43, 74, 0, 0], [0, 0, 0, 41, 34, 123, 0, 123, 123, 84, 66, 0, 0], [0, 0, 0, 38, 38, 0, 0, 82, 64, 0, 0, 31, 34, 0, 0, 0], [121, 121, 0, 34, 0, 59, 58, 8, 8, 14, 14, 0, 60, 0, 31, 74, 16, 0, 83, 0, 0, 72, 31, 31, 31, 0, 0, 0, 42, 31, 0, 51, 0, 31, 0, 34, 0, 34, 65, 0, 0, 0, 0, 34], [0, 0, 38, 38, 0, 0, 60, 58, 75, 124, 69, 81, 31, 43, 68, 81, 81, 81, 0, 81, 81, 81, 34, 29, 29, 69, 63, 61, 0, 59, 63, 8, 81, 0, 81, 81, 81, 0, 59, 0, 19, 0, 43, 59, 0, 0, 31, 0, 59, 0, 0, 0, 38, 52, 72, 34, 0, 73, 34, 66, 45, 30, 73, 73, 64, 73, 73, 0, 73, 42]], 'g2pA': [[0, 38, 38, 15, 0, 0, 38, 0, 0, 125, 19, 0, 125, 125, 34, 0, 52, 46, 0, 59, 0, 34, 0, 61, 34, 0, 61, 43], [0, 0, 0, 0, 36, 121, 36, 36, 121, 0, 121, 121], [42, 59, 74, 59, 0, 0, 121, 36, 36, 65], [31, 8, 8, 34, 0, 0], [60, 82, 47, 0, 61, 0], [43, 0, 60, 0, 0, 31, 0, 43, 42, 0, 0, 0, 0, 61, 61], [54, 61, 48, 0, 62, 46, 64, 44, 34, 0, 0, 64, 30, 30, 64], [123, 123, 84, 0, 0, 0, 0, 65, 34, 34, 123], [60, 69, 13], [0, 74, 0, 0, 42, 22, 0, 74], [60, 0, 0, 75, 68, 59, 15, 75], [43, 0, 43, 0, 71, 0, 8, 0, 43, 0, 42, 0, 0, 0, 0, 0, 42, 0, 43, 0, 0, 59, 0, 42, 0, 74, 43, 74, 0, 0], [0, 0, 38, 38, 0, 59], [75, 34, 0, 34, 73, 66, 0, 34, 30, 73, 73, 64, 73, 73, 0, 73, 42], [58, 75, 30, 0, 69, 81, 31, 43, 68, 81, 50, 81, 0, 81, 81, 81], [34, 29, 29, 69, 63, 61, 0, 59, 63, 8, 81, 0, 81, 81, 81], [], [0, 59, 0, 19, 43, 59, 0, 0, 31, 0, 59, 0, 0, 38, 52]], 'g0pD': [[0, 125, 38, 13, 125, 125, 34, 0, 52, 46, 0, 59, 0, 34, 0, 0, 42, 0, 38, 38], [0, 46, 0, 34, 0, 61, 61, 43, 0, 0, 0, 46], [0, 0, 38, 38, 59, 59, 0, 0, 0, 121, 36, 36, 65, 0, 0, 0, 0, 121, 36, 121, 121, 0, 36, 36], [31, 0, 52, 0, 0], [60, 82, 0, 69, 0, 82, 0], [0, 19, 0, 19, 0, 0, 64, 42, 22, 0, 74, 83, 43, 0, 83, 75, 43, 75, 15, 75, 75], [0, 42, 0, 0, 0, 0, 0, 42, 0, 43, 0, 0, 59, 43, 0, 0, 0, 43, 0, 0, 0, 8, 0, 43], [14, 0, 34, 29, 75, 0, 75, 75], [43, 0, 59, 0, 0, 31, 42, 42, 0, 0, 0, 0, 61, 61], [61, 61, 59, 0, 73, 46, 64, 34, 0, 0, 64, 30, 30, 64], [0, 0, 0, 65, 123, 0, 123, 123, 84]], 'orig': [[0, 38, 38, 15, 0, 0, 38, 0, 0, 125, 38, 13, 125, 125, 34, 0, 52, 46, 0, 59, 0, 34, 0, 61, 34, 0, 13, 13, 61, 43], [0, 0, 0, 0, 36, 121, 36, 36, 121, 0, 121, 121], [42, 59, 59, 59, 0, 0, 121, 36, 36, 65], [31, 0, 34, 0, 0], [31, 82, 82, 0, 82, 0], [43, 0, 59, 0, 0, 31, 42, 42, 0, 0, 0, 0, 61, 61], [61, 61, 59, 0, 73, 46, 64, 0, 34, 0, 0, 64, 30, 30, 64], [0, 0, 0, 41, 34, 123, 0, 123, 123, 84, 60, 0, 13, 69], [0, 74, 0, 0, 42, 22, 0, 74], [83, 43, 0, 75, 43, 75, 15, 75, 75], [43, 0, 43, 0, 71, 0, 8, 0, 43, 0, 42, 0, 0, 0, 0, 0, 42, 0, 43, 0, 0, 59, 0, 42, 0, 74, 43, 74, 0, 0], [0, 0, 38, 38, 0, 0, 60], [72, 34, 0, 73, 34, 66, 45, 30, 73, 73, 64, 73, 73, 0, 73, 42], [58, 75, 124, 69, 81, 31, 43, 68, 81, 81, 81, 0, 81, 81, 81], [34, 29, 29, 69, 63, 61, 0, 59, 63, 8, 81, 0, 81, 81, 81], [], [0, 59, 0, 19, 0, 43, 59, 0, 0, 31, 0, 59, 0, 0, 0, 38, 52]], 'g3pC': [[14, 0, 0, 38, 38, 13, 36, 36, 65, 24, 22, 0, 62, 0, 54, 34], [31, 0, 0, 0, 61, 59], [0, 37, 22, 15, 31, 0, 22, 8, 8, 14, 14, 0, 73, 60, 0, 50, 0, 42, 31, 83], [14, 0, 74, 31, 83, 63, 0, 38], [54, 54, 24, 0, 29, 65, 81], [60, 0, 34, 54, 45, 30, 52, 81, 64, 14, 54, 54, 8, 62, 83, 15, 59, 0], [0, 42, 0, 14, 14]], 'g2pB': [[0, 38, 38, 0, 0, 125, 38, 13, 125, 125, 34, 0, 34, 0, 61], [60, 59, 13, 0, 38, 38, 0, 13, 36, 0, 121, 0, 36], [22, 60, 54, 13, 0, 38, 65, 0, 121, 0, 0, 0, 54, 0, 121, 0, 34], [0, 62, 0, 38, 65, 60, 31, 0, 0, 0], [29, 31, 82, 0, 0, 0], [54, 0, 30, 59, 0, 0, 70, 0, 61, 60, 64, 13, 0, 38, 65, 29, 0, 65, 65, 0, 123, 123, 84], [0, 74, 0, 84, 22, 65, 0, 74, 0, 0, 0, 55], [0, 0, 65, 75, 68, 75, 15, 75, 75], [0, 42, 0, 72, 43, 0, 0, 59, 84, 0, 42, 43, 43, 0, 0, 13, 0, 43], [66, 62, 0, 38, 0, 65, 54, 0, 60, 33, 29, 14, 0, 45, 0, 0, 0, 59, 0, 0, 43, 0, 59, 75, 124, 8, 43, 13, 34, 30, 73, 73, 42, 63, 0, 65, 73, 34, 0, 37, 34, 42, 22, 0, 34, 123, 63, 8, 81, 43, 0, 59]], 'g0pA': [[0, 0, 38, 38, 0, 44, 0, 0, 38, 0, 0, 125, 38, 0, 0, 52, 125, 34, 0, 34, 0, 52, 46, 0, 59, 0, 34, 0, 61], [0, 0, 0, 0, 36, 36, 0, 59, 59, 0, 0, 0, 121, 36, 36, 65], [31, 0, 34, 0, 0, 0, 31, 82, 82, 0, 82, 0], [43, 0, 60, 0, 0, 31, 45, 42, 42, 0, 0, 0, 0, 61, 61], [54, 61, 59, 0, 62, 46, 64, 0, 34, 0, 0, 64, 30, 30, 64], [0, 0, 0, 41, 34, 48, 0, 44, 123, 123, 84], [0, 74, 0, 0, 42, 22, 0, 74, 63, 65, 43, 0, 75, 43, 75, 15, 75, 75], [43, 0, 43, 0, 71, 0, 8, 0, 43, 0, 42, 0, 0, 0, 0, 0, 42, 0, 43, 0, 0, 59, 19, 0, 0, 42, 0, 74, 43, 74, 0, 0], [0, 0, 38, 38, 0, 61], [72, 34, 0, 34, 66, 45, 30, 73, 73, 64], [58, 75, 124, 81, 31, 43, 0, 81, 0, 43, 81, 81, 0, 81, 81, 81], [34, 29, 29, 69, 63, 61, 0, 59, 54, 45, 8, 81, 0, 81, 81, 81], [0, 59, 0, 19, 0, 43, 59, 0, 0, 31, 0, 59, 0, 0, 0, 38, 52]], 'g4pC': [[0, 0, 38, 38, 0, 0, 34, 19, 0, 34, 0, 0, 43, 0, 68, 60, 0, 0, 52, 31, 31, 0, 0, 0, 70, 68, 62], [0, 59, 0, 63, 14, 0, 60, 0, 0, 63], [], [123, 24, 72, 43, 24, 0, 29, 0, 34], [], [61, 62, 34, 0, 0, 0, 72], [13, 0], [], [13, 31, 31, 0, 42, 0, 0, 31, 68], [], [14, 15, 36, 61, 62, 54, 61, 0, 61, 43], [], [120, 0, 72, 43], [122, 72, 31, 0, 0, 31, 68, 0, 72, 31, 0, 0, 31, 31]], 'g4pE': [[0, 74, 0, 0, 42, 22, 0, 74], [83, 43, 0, 75, 43, 75, 15, 75, 75], [43, 0, 43, 0, 71, 0, 8, 0, 43, 0, 42, 0, 0, 0, 0, 0, 42, 0, 43, 0, 0, 59, 31, 0, 34, 0, 0], [31, 82, 0, 82, 43], [43, 0, 59, 0, 0, 31, 42, 42, 0, 0, 0, 0, 61, 61], [121, 121, 0, 34, 0, 59, 58, 8, 8, 14, 14, 0, 60, 0, 31, 74, 16, 0, 83, 0, 0, 72, 31, 31, 31, 0, 0, 0, 42, 31, 0, 51, 0, 31, 0, 34, 0, 34, 65, 0, 0, 0, 0, 34], [54, 0, 59, 0, 0, 38, 38], [65, 42, 22, 0, 0, 0, 38, 38, 84, 0, 38, 38], [123, 42, 0, 38, 38, 0, 0, 38, 38, 0, 0, 0, 0, 0, 34, 8], [0, 0, 0, 0, 38, 38, 0, 123, 42, 0, 38, 38, 66, 45, 22, 42, 74, 31, 43], [0, 0, 0, 123, 42, 0, 38, 38, 0, 0, 45, 0, 0, 22, 54, 0, 0, 34, 24, 0]], 'g2pC': [[0, 0, 0, 38, 38, 34, 73, 0, 19, 0, 0, 43, 36, 36, 63, 19, 34, 0, 0, 68, 65, 65, 43, 0, 0, 54, 28, 45], [0, 0, 38, 38, 0, 0, 0, 36, 36, 0, 54, 54, 29, 34, 0, 0, 0, 41, 0, 54, 29, 34, 0, 0, 58, 31], [0, 60, 0, 34, 31, 31, 8, 8, 0, 0, 0, 64, 0, 43, 0, 0, 31, 51, 31, 0, 0, 0], [62, 8, 0, 8, 34, 0, 34, 22, 14, 0, 38, 38, 0, 14, 19, 31, 69, 0, 31, 0, 0, 0, 31, 0, 19, 0, 0, 0, 31, 0], [0, 31, 0, 0, 0, 31, 31, 0, 0, 14, 0, 73, 60, 19, 0, 0, 42, 0, 0, 74, 31, 0, 31, 0, 0, 0, 31, 0], [14, 62, 0, 14, 0, 83, 0, 73, 0, 0, 31, 0, 0, 0, 31, 0, 0, 0, 0, 0, 31, 0, 0, 0, 0, 0, 31, 0], [0, 69, 33, 73, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [31, 0, 42, 73, 0, 65, 0, 8, 0, 31, 0, 0, 31]], 'g4pB': [[0, 0, 38, 38, 15, 0, 0, 38, 0, 0, 125, 38, 13, 125, 125, 34, 0, 52, 46, 0, 59, 0, 34, 0, 61, 34, 0, 61, 43], [0, 0, 0, 0, 36, 121, 36, 36, 121, 0, 121, 121], [0, 59, 0, 0, 0, 59, 60, 0, 0, 121, 36, 36, 65], [31, 0, 34, 0, 0], [31, 0, 60, 82, 82, 0, 82, 0], [43, 0, 0, 31, 42, 42, 0, 0, 0, 0, 45, 59, 0, 61], [0, 61, 84, 0, 73, 46, 64, 0, 34, 0, 0, 64, 30, 30], [0, 0, 0, 65, 60, 123, 0, 123, 123, 84], [0, 74, 0, 0, 0, 22, 0, 74], [83, 43, 0, 75, 75, 43, 15, 75, 75], [84, 0, 43, 0, 0, 8, 0, 43, 0, 42, 0, 0, 0, 0, 59, 0, 0, 42, 0, 43, 0, 0, 59], [0, 0, 0, 70, 0, 0, 0, 74, 31, 0, 34, 68, 0, 0, 74, 0, 0, 60, 42, 0, 0, 31, 0, 31, 0, 0, 124, 67, 81, 19, 55, 0, 67, 0, 0, 0, 31, 59, 0, 0, 31]], 'g1pD': [[42, 36, 36, 31, 31, 0, 29, 8, 8, 34, 0, 0, 54, 0, 38, 14, 52, 0, 44, 0, 0, 38, 38], [36, 36, 62, 0, 0, 34, 0, 34, 0, 0, 34, 0, 38, 46, 0, 45, 0, 0, 29, 0, 31, 34, 0, 50, 84, 34], [0, 37, 34, 0, 0, 0, 34, 29, 84, 31, 31, 73, 0, 84, 0, 43, 0, 60], [54, 0, 0, 0, 8, 8, 0, 0, 0, 37, 34, 0, 65, 0, 57, 13, 0, 0, 38, 38, 0, 0, 42, 19, 0, 74, 31, 0, 37, 34, 0, 42, 31, 0]], 'g4pD': [[0, 0, 38, 38, 0, 34, 24, 19, 0, 36, 0, 0, 8, 0, 34, 0, 34], [0, 0, 84, 0, 15, 0, 0, 0, 38, 57], [43, 0, 60, 0, 43, 15, 52, 121, 0, 0, 0, 0, 125], [0, 84, 123, 0, 54, 81, 13, 0, 73, 60], [0, 73, 0, 36, 0, 67, 36, 36, 65], [14, 42, 22], [51, 0, 41, 22, 0, 62, 42, 0, 31, 0, 45, 45, 22, 31, 62], [0, 60, 0, 0, 0, 0, 60, 60, 68, 0, 60, 0, 31, 59, 60], [14, 8, 8, 65, 50, 0, 42, 0, 68, 60, 0, 45, 65, 54], [0, 61, 14, 60, 84, 54, 54, 0, 0, 59, 0, 31], [0, 48, 0, 59, 0, 31, 0, 48, 0, 0, 0, 0, 84, 0, 0, 31], [0, 24, 43, 0, 72, 34], [14, 60, 48, 0, 43, 0, 60, 48, 63, 28, 69], [0, 61, 14, 60, 0, 0, 52, 68, 0, 60, 0, 45, 59, 0, 43, 0, 59], [0, 61, 0, 19, 0, 69, 0, 0, 61], [0, 0, 0, 65, 0]], 'g2pE': [[36, 62, 0, 0, 17, 0, 13, 34, 13, 36, 42, 34, 0, 13, 51, 34, 0, 34, 0, 0, 0, 0, 0, 74, 74, 22], [62, 0, 42, 22, 17, 17, 121, 17, 36, 17, 36, 121, 72, 0], [54, 0, 0, 0, 0, 0, 43, 71, 36, 31, 36, 36, 36, 0, 125, 36, 63, 31, 0, 0, 42, 0, 16, 0], [36, 36, 62, 0, 0, 0, 65, 0, 30, 44, 36], [54, 0, 62, 59, 62, 62, 0, 63, 0, 0, 22, 34]], 'g3pA': [[0, 38, 38, 15, 0, 0, 38, 0, 0, 0, 0, 34, 0, 0, 125, 38, 13, 125, 46, 0, 0, 0, 13, 125, 34, 0, 34, 0, 61, 13, 13, 61, 43], [0, 0, 0, 0, 36, 36, 0, 121, 121, 0, 121, 121, 0, 59, 59, 0, 0, 0, 121, 36, 36, 65], [31, 0, 34, 0, 0, 29, 31, 82, 0, 82, 0], [43, 0, 59, 0, 0, 31, 0, 42, 54, 8, 61, 61, 0, 0, 0], [54, 61, 59, 0, 73, 46, 64, 0, 64, 30, 30, 64, 0, 0, 0, 41, 34, 123, 0, 123, 123, 84], [0, 19, 0, 0, 0, 64, 42, 22, 0, 74], [83, 43, 0, 75, 43, 75, 15, 44, 63, 75, 75], [43, 0, 43, 0, 71, 0, 0, 43, 0, 42, 0, 0, 0, 0, 0, 0, 42, 0, 74, 43, 0, 0], [121, 13, 34, 0, 59, 58, 8, 8, 14, 14, 54, 0, 60, 0, 31, 74, 16, 0, 83, 0, 0, 72, 31, 31, 31, 0, 0, 0, 42, 31, 0, 51, 0, 31, 0, 34, 0, 34, 0, 0, 0, 34], [65, 0, 0, 0, 70, 0, 42, 0, 0, 74, 31, 0, 34, 68, 0, 0, 74], [61, 42, 13, 0, 42, 0, 0, 31, 0, 31, 0, 0, 0, 14, 124, 67, 81, 14, 55, 0, 31, 0, 45, 0, 0, 31, 65, 65], [66, 0, 0, 38, 38, 0], [72, 34, 0, 73, 34, 63, 0, 54, 73, 73, 64, 73, 73, 0, 73, 42, 58, 75, 124, 81, 69, 0, 31, 43, 68, 81, 81, 81, 0, 81, 81, 81, 29, 69, 34, 63, 61, 0, 59, 63, 8, 81, 0, 81, 81, 81, 0, 0, 59, 0, 0, 43, 59, 0, 0, 31, 0, 45, 34, 0, 0, 0, 38, 38]], 'g1pB': [[0, 125, 38, 13, 125, 125, 34, 0, 46, 0, 34, 0, 61, 0, 44, 0, 0, 38, 38], [0, 0, 0, 0, 36, 121, 121, 121, 121, 0, 36, 36], [0, 59, 59, 0, 0, 0, 121, 36, 36, 65], [50, 31, 0, 34, 0, 0, 31, 82, 82, 0, 82, 0], [0, 19, 59, 0, 0, 31, 0, 42, 0, 0, 0, 0, 61, 61], [22, 59, 0, 73, 46, 64, 15, 64, 30, 30, 64], [0, 65, 60, 0, 123, 123, 84], [22, 0, 74, 0, 74, 0, 0], [75, 43, 75, 0, 75, 75, 0, 0, 13, 43], [0, 42, 0, 0, 0, 43, 43, 0, 0, 0, 43, 0, 0, 74, 42, 0, 43, 60, 13, 59], [0, 14, 0, 60, 0, 0, 31, 74, 16, 0, 121, 121, 0, 34, 0, 59, 58, 8, 8, 63, 0, 83, 0, 0, 72, 31, 34, 46, 42, 0, 31, 0, 0, 42, 31, 51, 0, 34, 0, 46, 0, 0, 34, 62], [0, 0, 0, 0, 38, 38, 0, 68], [63, 0, 73, 73, 64, 72, 34, 0, 73, 34], [81, 81, 69, 50, 8, 43, 58, 75, 63, 45, 69, 81, 31, 43], [81, 81, 69, 50, 8, 50, 34, 72, 69, 63, 30, 61, 0, 59], [0, 38, 52, 54, 0, 0, 0, 0, 59, 19, 0, 43, 0, 0, 0, 31]]}\n"
     ]
    }
   ],
   "source": [
    "# Creating vector of sentences\n",
    "\n",
    "vector_dict = {}\n",
    "for key, value in question_mapping.items():\n",
    "    vector_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        vector_dict[key][student] = []\n",
    "        for sent in answer:\n",
    "            words = sent.split(' ')\n",
    "            temp_list = []\n",
    "            for w in words:\n",
    "                for cluster_key, cluster_value in clust_dict.items():\n",
    "                    if w in clust_dict[cluster_key]:\n",
    "                        temp_list.append( cluster_key)\n",
    "            vector_dict[key][student].append(temp_list)\n",
    "            \n",
    "for k, v in vector_dict.items():\n",
    "    print(k, '    ', v)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_name = {}\n",
    "rep = 0\n",
    "for key, value in vector_dict.items():\n",
    "    for student, vector in value.items():\n",
    "        for v in vector:\n",
    "            vector_name[tuple(v)] = rep\n",
    "            rep+=1\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskc      {'g0pC': [0, 1, 2, 3, 4, 5, 6, 7, 8], 'g0pE': [9], 'g1pA': [10, 11, 12, 76, 14, 15, 16, 17, 18, 19, 20], 'g3pB': [21, 22, 23, 24, 25, 26, 27, 28, 29], 'g0pB': [30, 74, 153, 108, 137, 78, 133, 134, 82, 39, 40, 138, 42], 'g2pA': [43, 153, 45, 46, 47, 48, 49, 50, 51, 133, 53, 82, 55, 56, 57, 86, 906, 60], 'g0pD': [61, 62, 63, 64, 65, 66, 67, 68, 137, 70, 71], 'orig': [72, 153, 74, 155, 76, 137, 78, 79, 133, 134, 82, 83, 84, 85, 86, 906, 118], 'g3pC': [89, 90, 91, 92, 93, 94, 95], 'g2pB': [96, 97, 98, 99, 100, 101, 102, 103, 104, 105], 'g0pA': [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118], 'g4pC': [119, 120, 906, 122, 906, 124, 125, 906, 127, 906, 129, 906, 131, 132], 'g4pE': [133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143], 'g2pC': [144, 145, 146, 147, 148, 149, 150, 151], 'g4pB': [152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163], 'g1pD': [164, 165, 166, 167], 'g4pD': [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'g2pE': [184, 185, 186, 187, 188], 'g3pA': [189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'g1pB': [202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217]}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Creating answer vectors.\n",
    "\n",
    "pro_dict = {}\n",
    "for key, value in vector_dict.items():\n",
    "    pro_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        pro_dict[key][student] = []\n",
    "        for v in answer:\n",
    "            ans = tuple(v)\n",
    "            pro_dict[key][student].append(vector_name[ans])\n",
    "\n",
    "for key, value in pro_dict.items():\n",
    "    print(key, '    ', value)\n",
    "    break\n",
    "    \n",
    "print(len(pro_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyfpgrowth\n",
    "inp = [\"taske\", \"taska\", \"taskb\", \"taskc\", \"taskd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performing FP_Growth Algorithm\n",
    "\n",
    "def fp_growth(transactions):\n",
    "    patterns = pyfpgrowth.find_frequent_patterns(transactions, 3)\n",
    "    frequent_list = []\n",
    "    for p in patterns:\n",
    "        if len(p) < 3:\n",
    "            continue\n",
    "        else:\n",
    "            frequent_list.append(list(p))\n",
    "    return frequent_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_sub(sub, lst):\n",
    "    ln = len(sub)\n",
    "    for i in range(len(lst) - ln + 1):\n",
    "        if all(sub[j] == lst[i+j] for j in range(ln)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(frequent_list):\n",
    "    output_dict= {}\n",
    "    for lst in frequent_list:\n",
    "        for k, v in pro_dict.items():\n",
    "            for name, vec in v.items():\n",
    "                if is_sub(lst,vec):\n",
    "                    if k not in output_dict:\n",
    "                        output_dict[k] = [name]\n",
    "                    else:\n",
    "                        output_dict[k].append(name)\n",
    "    return output_dict\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taske      {'g2pB', 'g1pB', 'g0pE', 'orig'}\n",
      "taska      {'g4pC', 'g3pC', 'g2pC', 'g0pE', 'orig'}\n",
      "taskd      {'g4pC', 'g2pA', 'g3pA'}\n"
     ]
    }
   ],
   "source": [
    "# Final output from our script.\n",
    "\n",
    "final= {}\n",
    "for task in inp:\n",
    "    transactions = []\n",
    "    for k, v in pro_dict.items():\n",
    "        if k == task:\n",
    "            for name, vec in v.items():\n",
    "                transactions.append(vec)\n",
    "            frequent_list = fp_growth(transactions)\n",
    "    output_dict = output(frequent_list)\n",
    "    for key, value in output_dict.items():\n",
    "        final[key] = set(value)\n",
    "        \n",
    "\n",
    "for i, v in final.items():\n",
    "    print(i, '    ', v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xl = pd.ExcelFile(\"corpus_final.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = xl.parse(\"File list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = df[['File','Category']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is :  0.9\n",
      "Recall is :  0.5232558139534887\n",
      "Accuracy is :  0.9403372243839171\n",
      "F1 Score is :  0.6617647058823533\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "fp = 0\n",
    "for key, value in final.items():\n",
    "    for v in value:\n",
    "        ans = v+key+'.txt'\n",
    "        head = key\n",
    "        for index, row in c.iterrows():\n",
    "            if row['File'].split('_')[1].split('.')[0] == head:\n",
    "                if row['File'].split('_')[0] == v:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        tp+=1\n",
    "                    else:\n",
    "                        fp+=1\n",
    "                else:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        fn +=0.1\n",
    "                    else:\n",
    "                        tn+=1\n",
    "\n",
    "precision = float(tp/(tp+fp))                        \n",
    "print('Precision is : ', precision)\n",
    "recall = float(tp/(tp+fn))\n",
    "print('Recall is : ', recall)\n",
    "print('Accuracy is : ', (tp+tn)/(tp+fn+tn+fp))\n",
    "print('F1 Score is : ', 2*precision*recall/(precision+recall))\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
