{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.cluster import KMeans\n",
    "from numbers import Number\n",
    "from pandas import DataFrame\n",
    "import sys, codecs, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autovivify_list(dict):\n",
    "  def __missing__(self, key):\n",
    "    '''Given a missing key, set initial value to an empty list'''\n",
    "    value = self[key] = []\n",
    "    return value\n",
    "\n",
    "  def __add__(self, x):\n",
    "    '''Override addition for numeric types when self is empty'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return x\n",
    "    raise ValueError\n",
    "\n",
    "  def __sub__(self, x):\n",
    "    '''Also provide subtraction method'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return -1 * x\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_word_vector_matrix(vector_file, n_words):\n",
    "  '''Return the vectors and labels for the first n_words in vector file'''\n",
    "  numpy_arrays = []\n",
    "  labels_array = []\n",
    "  with codecs.open(vector_file, 'r', 'utf-8') as f:\n",
    "    for c, r in enumerate(f):\n",
    "      sr = r.split()\n",
    "      labels_array.append(sr[0])\n",
    "      numpy_arrays.append( numpy.array([float(i) for i in sr[1:]]) )\n",
    "\n",
    "      if c == n_words:\n",
    "        return numpy.array( numpy_arrays ), labels_array\n",
    "\n",
    "  return numpy.array( numpy_arrays ), labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_word_clusters(labels_array, cluster_labels):\n",
    "  '''Return the set of words in each cluster'''\n",
    "  cluster_to_words = autovivify_list()\n",
    "  for c, i in enumerate(cluster_labels):\n",
    "    cluster_to_words[ i ].append( labels_array[c] )\n",
    "  return cluster_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=252, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector_file = '/Users/varunnandu/glove/vectors.txt' \n",
    "n_words = int(1262) # Number of words to analyze \n",
    "reduction_factor = float(0.2) # Amount of dimension reduction {0,1}\n",
    "n_clusters = int( n_words * reduction_factor ) # Number of clusters to make\n",
    "df, labels_array = build_word_vector_matrix(input_vector_file, n_words)\n",
    "kmeans_model = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans_model.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_labels  = kmeans_model.labels_\n",
    "cluster_inertia   = kmeans_model.inertia_\n",
    "cluster_to_words  = find_word_clusters(labels_array, cluster_labels)\n",
    "\n",
    "clusters = []\n",
    "for c in cluster_to_words:\n",
    "    clusters.append(cluster_to_words[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ['the', 'of', 'is', 'to', 'and', '05', 'in', 'that', 'be', 'as', 'it', 'by', 'are', 'for', 'can', 'this', 'or', 'used', 'which', 'an', 'vector', 'pagerank', 'term', 'on', 'from', 'classes', 'has', 'with', 'have', 'one', '06', 'inheritance', 'problems', 'optimal', 'each', 'probabilities', 'google', 'also', 'class', 'number', 'links', 'given', 'we', 'these', 'example', 'more', 'new', 'where', 'if', 'any', 'methods', 'solutions', 'sub', 'into', 'means', 'at', 'known', 'computer', 'objects', 'been', 'values', 'will', 'no', 'there', 'same', 'they', 'program', 'another', 'derived', 'order', 'often', 'based', 'could', 'mathematical', 'after', 'science', 'base', 'algebraic', 'sense']\n",
      "17      ['probability', 'theory', 'prior']\n",
      "18      ['programming', 'dynamic']\n",
      "28      ['h0k', 'he', 'ubx', 'hhk', 'hij', 'hijses']\n",
      "29      ['all', 'common']\n",
      "31      ['theorem', 'bayes']\n",
      "34      ['page', 'other', 'pages', 'web']\n",
      "35      ['document', 'query']\n",
      "40      ['documents', 'vectors']\n",
      "43      ['information', 'retrieval']\n",
      "45      ['space', 'model']\n",
      "49      ['subproblems', 'substructure', 'overlapping', 'exhibit']\n",
      "51      ['terms', 'words']\n",
      "52      ['called', 'sometimes']\n",
      "56      ['not', 'does']\n",
      "58      ['problem', 'solution', 'find', 'solve', 'need', 'you']\n",
      "59      ['conditional', 'marginal', 'relates']\n",
      "61      ['between', 'original', 'cosine', 'angle']\n",
      "64      ['may', 'when', 'certain', 'observed', 'applied']\n",
      "65      ['value', 'its']\n",
      "68      ['using', 'then', 'would', 'calculated']\n",
      "70      ['events', 'two', 'random']\n",
      "72      ['object', 'oriented']\n",
      "73      ['about', 'specific']\n",
      "74      ['algorithm', 'link', 'analysis']\n",
      "78      ['many', 'code', 'their', 'frequencies', 'inbound', 'outbound']\n",
      "81      ['method', 'solving']\n",
      "83      ['search', 'bellman', 'child', 'typically', 'little', 'having', '1940s', 'engines', 'parent', 'richard', 'controlled', 'comparing', 'normally', 'occurrence', 'provided', 'specialised']\n",
      "86      ['was', 'first']\n",
      "87      ['8i', '8w', '8j', 'b8', '98', 'h8', 'd8', 't8', '8n', 'x8', 'w8', '7w', 'k8', '48', '7o', '7p', '79', '84', '38', '7v', '8s', 'j8', '28', '78', '8r', '7f', '7y', '9s', 'v7', '18', '7c', '7h', '7k', '7b', 'allows', 'every', 'i7', 'main', '19', '7e', '7s', '7x', '83', '_8', '77', '7m', 'c7', 'generally', 'see', 'zs', '6a', '6b', '6v', '72', '7l', 'b7', 'factor', 'following', 'vote', '6e', '73', '76', '8_', '96', 'assumptions', 'dx', 'fs', 'md', 'rd', 'zn', '37', '67', '6i', '70', '93', 'ac', 'd7', 'fi', 'formed', 'g6', 'ii', 'iv', 'j6', 'lt', 'wz', 'xl', 'xt']\n",
      "89      ['different', 'vocabulary', 'occurs']\n",
      "90      ['such', 'represented', 'well']\n",
      "91      ['8x', '8e', '8v', '8z', '8b', 'l8', 'c8', 'p8', '8l', '8m', '8p', 's8', '9t', 'i8', '8k', '8o', '8t', 'a8', 'f8', '88', '89', 'u8', 'r7', 'p9', '68', '81', 'l7', 'hence', 'whilst', 'calculating', 'field', 'whole', 'z6', 'angles', 'content', 'counts', 'four', 'just']\n",
      "92      ['up', 'computed', 'data', 'determine', 'do', 'made', 'out', 'create', 'found', 'try', 'manipulation']\n",
      "94      ['8q', 'o8', '8h', '8d', '8f', '8u', '8g', 'y8', 'q8', 'z8', '7d', 'b9', 'models', 'element', 'usually', '7u', 'relationship', 'useful', 'what', '7t', 'j7', '82', 'ja', 'n9', 'jj', 'second', 'acts', 'cx', 'df', 'fu', 'jm', 'qd']\n",
      "95      ['student', 'event', 'diagnosis', 'correct', 'proposed', 'formal']\n",
      "96      ['time', 'but', 'some', 'overall', 'won', 'save', 'stored', 'cases']\n",
      "97      ['way', 'form']\n",
      "99      ['being', 'identifiers', 'expressed', 'populations', 'subsets', 'instances', 'proportions']\n",
      "102      ['word', 'languages', 'categorization', 'mathematics']\n",
      "103      ['fruit', 'apple', 'acceptable', 'abstraction']\n",
      "105      ['9j', '9x', '8y', '9n', '9p', '9f', '9w', '9l', '9v', '9k', '80', '99', '9z', '2099e', '9u', 'j9', '9c', 't9', '92', 'apples', 'orange', 'etc', 'control', 'de', 'ba', 'context', 'conversely', 'involves', 'numeric', 'precisely', 'smaller', 'co', 'f1', 'nq', 'st', 'weightingthe']\n",
      "106      ['compute', 'posterior']\n",
      "107      ['however', 'most', 'therefore', 'calculate', 'distribution', 'system', 'considered']\n",
      "108      ['so', 'say']\n",
      "109      ['inherit', 'attributes', 'solved', 'variables', 'divided']\n",
      "110      ['use', 'instead', 'concept', 'formula', 'valid', 'constant', 'equal', 'appears', 'lost', 'remembered']\n",
      "111      ['importance', 'within', 'relative', 'definition', 'dimensionality', 'webpage']\n",
      "112      ['properties', 'both', 'beliefs', 'subclasses', 'degrees', 'unique', 'types', 'behavior', 'behaviours']\n",
      "114      ['9e', '9m', 'g8', '8a', '9g', '9h', 'h9', '9i', 'o9', '9y', '000226815', '9q', 'c9', 'since', 'x9', 'q9', '9d', '9o', '95', 'describe', '29', '49', '85', 'dp', 'y9', 'entities', 'ir', '75', '9_', 'i9', 'k9', 'm9', 'q7', '69', 'a1', 'bayesians', 'pr', 's9', 'ff', 'processing', 'uh', 'xp', 'bw', 'equation', 'hg', 'mechanism', 'ny', 'postgraduate', 'transport', 'yz', '60', 'animals', 'ch', 'debates', 'eh', 'fd', 'features', 'further', 'get', 'jz', 'nodes', 'patented', 'pieces', 'public', 'qs', 'qz', 'recursively', 'superclasses', 'without', 'yr']\n",
      "115      ['because', 'generalization']\n",
      "116      ['how', 'linked']\n",
      "118      ['r8', 'm8', 'n8', '87', 'v8', '9b', 'u9', '97', 'v9', 'w7', '7a', '7q', '7r', '58', '7z', '8c', 'a9', '9r', 'e8', 'e9', 'f7', 'g9', 'l9', 'y7', '7g', '7i', '86', '9a', 'collection', 'd9', 'f9', '09', '6m', 'm7', 'r9', '08', '10', '90', 'a7', 'available', 'g7', 'h7', 'key', 'u7', 'z7', 'z9', '59', '7_', '7n', '91', 'e7', 'k7', 'n7', 'om', 'w9', 'ae', 'basically', 'ht', 'idea', 'kw', 'lg', 'memoization', 'popular', 'qw', 'ra', 'research', 'rj', 'ro', 'solves', 'ss', '17', '4e', '5x', '6l', '6r', '74', '_9', 'bd', 'bm', 'd6', 'da', 'dc', 'es', 'evidence', 'fj', 'fk', 'functions', 'fv', 'gb', 'gr', 'h1', 'h6', 'hc', 'il', 'inherited', 'io', 'kf', 'km', 'ku', 'kx', 'language', 'make', 'measure', 'mt', 'og', 'pp', 'qf', 'qj', 'ri', 'surfer', 'together', 'type', 'ui', 'un', 'uq', 'vl', 'wa', 'ya', 'zp', '<unk>']\n",
      "119      ['set', 'hyperlinked']\n",
      "120      ['computing', 'take', 'product', 'train', 'large', 'reciprocal', 'references', 'car', 'discuss', 'engineering', 'mango', 'quotations']\n",
      "122      ['best', 'needs', 'decisions']\n",
      "124      ['non', 'zero', 'several', 'frequency']\n",
      "126      ['process', 'important', 'results', 'uses', 'high', 'name', 'rank', 'sites']\n",
      "127      ['bayesian', 'interpretations', 'frequentist']\n",
      "128      ['existing', 'reuse', 'help']\n",
      "130      ['similar', 'share', 'lot', 'interfaces', 'modules', 'sufficiently']\n",
      "131      ['ways', 'false', 'describes', 'applications', 'negative', 'larger', 'associated', 'recursive']\n",
      "132      ['already', 'defined']\n",
      "133      ['approach', 'them', 'others', 'themselves', 'extend', 'needed', 'updated', 'chosen', 'due', 'add', 'said']\n",
      "135      ['optimization', 'synonym']\n",
      "136      ['particular', 'connection']\n",
      "138      ['depends', 'like', 'application', 'similarities', 'upon', 'scale', 'specified', 'articles']\n",
      "139      ['instance', 'exhibition', 'observations', 'produced']\n",
      "140      ['keywords', 'single', 'longer', 'phrases']\n",
      "142      ['000222005', '000641574', '000782035', '00145284']\n",
      "143      ['000714138', '00116851', '00133258', '00139828', '00166282']\n",
      "144      ['000837489', '00078398', '00154063']\n",
      "145      ['00105573', '000218071', '000346468', '000722866', '00118384', '00122644', '98124e']\n",
      "146      ['00127245', '00027091', '000641772', '00127034']\n",
      "147      ['ancestor', 'exposed', 'those', 'adding']\n",
      "148      ['plan', 'action', 'finding']\n",
      "149      ['structure', 'kind']\n",
      "150      ['superclass', 'only', 'subclass']\n",
      "151      ['than', 'less', 'much', 'account', 'cognitive', 'economy']\n",
      "152      ['weighting', 'higher', 'actual', 'characteristics', 'your', 'factors', 'subproblem', 'users', 'visits', 'include', 'relevance', 'relevant', 'website', 'access', 'affect']\n",
      "153      ['000104496', '000349485', '0015892']\n",
      "154      ['000112297', '000510361', '000822361', '000851915']\n",
      "155      ['000118776', '000154858', '000740185', '00122127', '00158507']\n",
      "156      ['000121415', '000289281', '000741238', '00121285', '00127489']\n",
      "157      ['000121931', '000154344', '000597976', '00132224']\n",
      "158      ['000128402', '000935097', '000997195', '00159539']\n",
      "159      ['000146166', '000228113', '000784815', '000914112']\n",
      "160      ['000149611', '000254484', '000342545', '000486314', '000717298', '28277e', '7908e', '79304e']\n",
      "161      ['000173975', '000434826', '000997342', '00134573', '00138859']\n",
      "162      ['000176249', '000923061', '0011547', '00150916']\n",
      "163      ['000204662', '000233989', '00162791']\n",
      "164      ['000208043', '000388528', '000972417', '00130591', '00154554', '63164e']\n",
      "165      ['000209893', '000468307', '000606068', '000658771', '00147916']\n",
      "166      ['000213784', '00044146', '000679629', '00102065', '00130641']\n",
      "167      ['000218611', '000627347', '000818812', '00147324']\n",
      "168      ['000228605', '000247751', '000507011', '000510669', '00132182']\n",
      "169      ['000230336', '000309389', '000658096', '0010244', '00143611']\n",
      "170      ['000233216', '000237438', '000302909', '000672392', '00121509']\n",
      "171      ['00024084', '000253858', '000306806']\n",
      "172      ['000251048', '000419433', '0009751', '00158112']\n",
      "173      ['000253155', '000558035', '00060477', '000721091', '00122734', '00143099']\n",
      "174      ['000253817', '000354644', '000479967', '00160269']\n",
      "175      ['000257429', '000379887', '000873691', '0014425', '00144738']\n",
      "176      ['000281587', '000692842', '000863904', '00153979']\n",
      "177      ['00028446', '000918943', '00120731', '00134052', '00135353', '0015764', '74935e', '77299e', '07', '000295394']\n",
      "178      ['00028579', '000606723', '000679533', '00127091']\n",
      "179      ['000288034', '000727566', '00145348']\n",
      "180      ['000288376', '00070198', '00105603', '00159964']\n",
      "181      ['00029439', '000388454', '000599943']\n",
      "182      ['0002997', '000339263', '00062685', '000767073']\n",
      "183      ['000344981', '000664931', '00067521', '00104599']\n",
      "184      ['000373652', '00038978', '000392118', '00160403']\n",
      "185      ['000385199', '00112502', '00116003', '00122709', '00125393']\n",
      "186      ['000392922', '000689932', '00116315', '00124763']\n",
      "187      ['000393385', '000533912', '000661417', '000699741']\n",
      "188      ['000404928', '000681381', '00111769', '00156054']\n",
      "189      ['000407494', '000654478', '00106799', '0015844']\n",
      "190      ['000429939', '00110349', '00124217']\n",
      "191      ['000437583', '00101139', '00106998']\n",
      "192      ['000438051', '000464908', '000750848', '00152028', '41461e', '69545e']\n",
      "193      ['000454297', '000615239', '000965391', '00123691']\n",
      "194      ['000466403', '00118882', '00127242', '00148223']\n",
      "195      ['00046674', '00118601', '00162762']\n",
      "196      ['000481291', '00053947', '000955627', '00103384', '00107373', '00121033', '00125502', '00159165', '0669e']\n",
      "197      ['000509222', '00117286', '0016061', '00162254']\n",
      "198      ['000515494', '000920251', '00142694']\n",
      "199      ['000521099', '00113677', '00120606', '00129875']\n",
      "200      ['000543594', '000788925', '000943677', '00159783', '00163446']\n",
      "201      ['000555889', '000568793', '00146592']\n",
      "202      ['000566388', '00095051', '00133235', '00143176', '0016119']\n",
      "203      ['000592722', '00076664', '00109647', '00165102']\n",
      "204      ['000624961', '000769519', '000820195', '000948308', '00149124']\n",
      "205      ['000723977', '000797545', '00126601', '00153604']\n",
      "206      ['00075486', '000993489', '00104788', '00150931']\n",
      "207      ['000766635', '00109457', '0122e']\n",
      "208      ['000798503', '000861262', '000908618', '00148554', '1804e']\n",
      "209      ['000828879', '000884418', '00146811']\n",
      "210      ['000894328', '00147126', '00149773', '00153857']\n",
      "211      ['000927189', '00110873', '00123337']\n",
      "212      ['000967188', '00104602', '00148124']\n",
      "213      ['000970411', '00112897', '00132652']\n",
      "214      ['000978992', '00100001', '00160493']\n",
      "215      ['00112648', '001343', '00134634', '0015882']\n",
      "216      ['00137624', '00141866', '00142988', '00159927']\n",
      "218      ['general', 'referred', 'seen']\n",
      "220      ['result', 'bottom', 'central', 'role', 'appear', 'occurring', 'shares']\n",
      "221      ['world', 'wide']\n",
      "222      ['assigned', 'should']\n",
      "223      ['assigns', 'patient', 're', 'symptoms', 'even', 'intended', 'relation', 'cannot', 'consider', 'group', 'again']\n",
      "224      ['hierarchy', 'represent', 'relationships']\n",
      "225      ['keyword', 'graph', 'originally', 'invented', 'greater']\n",
      "226      ['match', 'positive', 'disagree', 'might', 'matches', 'entity', 'frequentists', 'reach', 'substrings', 'vanishing']\n",
      "227      ['path', 'patent', 'comes', 'goal', 'shortest', 'among']\n",
      "228      ['similarity', 'poor', 'small']\n",
      "229      ['site', 'internet', 'ranking', 'engine', 'algorithms', 'meaning', 'denotes', 'toolbar', 'influence', 'modern', 'through']\n",
      "230      ['trousers', 'plays', 'topic', 'girl', 'popularity', 'possible', 'wearing', 'yo', 'computation', 'design', 'very', 'who', 'accurate', 'chance', 'happened', 'modification', 'previous', 'right', 'theoretical', 'true']\n",
      "232      ['either', 'accomplished', 'dividing', 'overriding', 'learning', 'shared', 'human', 'replacing', '1953']\n",
      "233      ['f2', 'f3', 'f4', 'over']\n",
      "234      ['naive', 'x7', 'numerical', '39', '7j', 'hijubx', 'university', 'must', 'rq', 'stanford', 'circle', 'f5', 'had', 'naturally', 'qx', 'our', 'pre', 'rh', 'ru', 'yn', '1g', 'gi', 'qu', 'refined', 'rz', 'shape', 'sn', 'storing', 'us', 'weight']\n",
      "235      ['tf', 'idf', 'schemes']\n",
      "236      ['according', 'assign']\n",
      "237      ['dimension', 'separate', 'corresponds']\n",
      "238      ['representing', 'text']\n",
      "239      ['weights', 'developed']\n",
      "241      ['indexing', 'rankings', 'relevancy', 'filtering', 'smart']\n",
      "243      ['step', 'three']\n",
      "244      ['support', 'provides', 'representation', 'basic', 'thus', 'powerful', 'technique', 'solvable']\n",
      "245      ['takes', 'around', 'debate', 'down', 'statistics', 'students', 'top', 'foundations', 'below', 'wear', 'described']\n",
      "246      ['advantage', 'complexity', 'measuring', 'reducing', 'purpose', 'total', 'distinct', 'seed', 'uncertainty', 'givenis', 'happening']\n",
      "247      ['simple', 'until', 'case', 'clicking', 'person', 'prob', 'randomly']\n",
      "248      ['index', 'poorly', 'queries', 'systems', 'container', 'fleshy', 'long', 'systemdocument']\n",
      "249      ['schedule', 'finalized']\n",
      "250      ['thomas', 'law', 'rev']\n",
      "251      ['polymorphism', 'view', 'dual']\n"
     ]
    }
   ],
   "source": [
    "clust_dict = {}\n",
    "for clus in clusters:\n",
    "    if len(clus) == 1:\n",
    "        if 0 not in clust_dict:\n",
    "            clust_dict[0] = clus\n",
    "        else:\n",
    "            clust_dict[0] += clus\n",
    "    else:\n",
    "        clust_dict[clusters.index(clus)] = clus\n",
    "for key, value in clust_dict.items():\n",
    "    print(key, '    ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, nltk, re\n",
    "\n",
    "# Open a file\n",
    "path = \"/Users/varunnandu/Desktop/plagiarism-detection-nlp/DATA-NLP\"\n",
    "dirs = os.listdir( path )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_mapping = dict() # Mapping to question dictionary\n",
    " # Mapping to student as key and answer as value\n",
    "\n",
    "for file in dirs:\n",
    "    if file == '.DS_Store':\n",
    "            continue\n",
    "    path_to_file='/Users/varunnandu/Desktop/plagiarism-detection-nlp/DATA-NLP/'\n",
    "    file_name = file\n",
    "    split_name = file.split('_')\n",
    "    student_name = split_name[0]\n",
    "    question_number = split_name[1].split('.')[0]\n",
    "    if question_number not in question_mapping:\n",
    "        question_mapping[question_number] = {}\n",
    "    path_to_file += file_name\n",
    "    with open(path_to_file, 'r', errors = 'ignore') as f:\n",
    "        mylist = f.read()\n",
    "        sent_tokenize_list = nltk.sent_tokenize(mylist)\n",
    "        temp = []\n",
    "        for i in sent_tokenize_list:\n",
    "            sent = i.lower()\n",
    "            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "            temp.append(sent)\n",
    "        question_mapping[question_number][student_name] = temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskc      {'g0pC': [[0, 0, 45, 45, 0, 0, 0, 35, 0, 0, 0, 51, 0, 0, 0, 0, 83], [0, 35, 0, 0, 0, 0, 102, 0, 237], [0, 0, 0, 68, 0, 0, 124, 0, 102, 237], [0, 0, 0, 133, 0, 0, 0, 0, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 58, 0, 0, 61, 228, 61, 152, 70, 40], [0, 0, 58, 0, 61, 0, 70, 40, 0, 120, 0, 0, 133], [0, 35, 0, 83, 45, 0, 35, 0, 0, 0, 90, 0, 0, 68, 58, 58, 0, 35, 0, 0, 0, 61, 138, 0, 152, 35], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 96, 0, 0, 133, 120, 0, 61, 138, 61, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 58, 0, 110, 0, 68, 0, 0, 0], [0, 245]], 'g0pE': [[0, 244, 0, 119, 0, 40, 0, 40, 0, 29, 0, 45, 0, 0, 0, 0, 0, 45, 0, 45, 45, 0, 0, 0, 0, 43, 43, 114, 40, 0, 35, 35, 0, 35, 0, 86, 0, 244, 0, 45, 243, 0, 0, 0, 0, 251, 0, 248, 0, 40, 0, 0, 0, 0, 45, 0, 0, 35, 118]], 'g1pA': [[0, 0, 45, 45, 0, 0, 0, 45, 0, 0, 224, 238, 40, 0, 0, 0, 87, 0, 40, 0, 99, 0, 139, 248, 51], [65, 131, 152, 43, 241, 43, 43, 241, 0, 241, 241], [0, 0, 0, 45, 40, 0, 90, 0, 40], [0, 237, 237, 0, 237, 0], [0, 65, 0, 0, 0, 124, 124, 0, 0, 89, 0, 0, 35], [124, 89, 131, 0, 0, 239, 0, 91, 0, 0, 0, 0, 0, 0, 239], [0, 0, 0, 122, 0, 235, 0, 235, 235, 0, 124, 35, 124, 152], [0, 45, 0, 0, 0, 0, 92, 0, 241, 241, 0, 40, 0, 225, 83, 68, 0, 87, 0, 35, 138, 17, 0, 83, 0, 61, 35, 0, 0, 0, 35, 0, 90, 0, 0, 149, 0, 0, 0, 0, 40, 0, 0, 0, 91, 61, 0, 35, 0], [0, 0, 45, 45, 86, 0, 0, 0, 0, 0, 0, 0, 124, 35, 124, 45], [0, 0, 45, 0, 0, 73, 239, 0, 0, 35, 40, 0, 0, 0], [0, 0, 45, 0, 0, 73, 239, 0, 91, 0, 91, 0, 0, 0, 107, 92, 56, 152, 0]], 'g3pB': [[0, 0, 120, 0, 0, 94, 0, 0, 81, 0, 58, 0, 43, 43, 0, 0, 0, 29, 0, 0, 0, 0, 243, 0, 119, 17, 0], [0, 0, 45, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45], [0, 0, 0, 45, 45, 35, 0, 90, 0, 0], [111, 0, 0, 0, 237, 237, 0, 237, 0, 0, 0, 0, 83, 140, 102, 225, 0], [0, 0, 0, 111, 0, 35, 0, 65, 0, 0, 0, 0, 124], [0, 0, 89, 0, 0, 35, 65, 65, 0, 124, 124], [0, 107, 116, 152, 0, 35, 0, 0, 225, 83, 0, 61, 65, 0, 0, 61, 61, 0, 40, 0, 0, 107, 110, 0, 0, 152, 61], [0, 0, 45, 45, 107, 0, 56, 114, 65, 0, 0, 228, 228, 0, 248, 40, 0, 248, 90, 0, 0, 0, 51, 56, 56, 131, 226, 226, 64, 0, 73, 0, 51, 111, 51, 133, 0, 40, 0, 222, 226, 96, 110, 89, 64, 131, 131, 226], [0, 0, 0, 0, 34, 94, 0, 0, 0, 0, 0, 133, 0, 0, 45, 45, 0, 0, 0, 0, 92, 0, 0, 0]], 'g0pB': [[0, 45, 45, 0, 0, 0, 45, 0, 238, 238, 40, 0, 0, 218, 0, 0, 0, 40, 0, 99, 90, 0, 0, 0, 248, 51], [65, 86, 110, 86, 0, 0, 241, 43, 43, 107], [0, 0, 0, 0, 43, 241, 43, 43, 241, 0, 241, 241], [35, 0, 90, 0, 0, 0, 0, 237, 237, 0, 237, 0], [0, 0, 89, 0, 0, 35, 65, 65, 0, 0, 0, 0, 124, 124], [124, 89, 131, 0, 120, 0, 0, 0, 0, 0, 0, 239, 0, 0, 239], [0, 111, 0, 0, 138, 0, 0, 138], [83, 51, 0, 140, 51, 140, 0, 140, 140], [0, 0, 51, 0, 133, 0, 0, 0, 51, 0, 111, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 89, 0, 0, 0, 246, 51, 220, 0, 0], [0, 0, 0, 122, 0, 235, 0, 235, 235, 152, 95, 0, 0], [0, 0, 0, 45, 45, 0, 0, 73, 239, 0, 0, 35, 40, 0, 0, 0], [241, 241, 0, 40, 0, 225, 83, 0, 0, 68, 68, 0, 87, 0, 35, 138, 17, 0, 83, 0, 0, 91, 61, 0, 35, 0, 0, 0, 61, 35, 0, 0, 0, 35, 0, 90, 0, 0, 149, 0, 0, 0, 0, 40], [0, 0, 45, 45, 0, 0, 87, 83, 140, 234, 105, 226, 35, 51, 102, 226, 226, 220, 0, 131, 226, 226, 40, 0, 130, 105, 96, 89, 0, 89, 96, 0, 131, 0, 131, 131, 226, 0, 0, 0, 0, 0, 51, 220, 0, 0, 35, 0, 110, 0, 0, 0, 45, 244, 248, 40, 0, 248, 90, 115, 0, 0, 228, 228, 0, 228, 120, 0, 120, 111]], 'g2pA': [[0, 45, 45, 0, 0, 0, 45, 0, 0, 0, 97, 0, 238, 238, 40, 0, 0, 0, 0, 218, 0, 40, 0, 99, 90, 0, 248, 51], [0, 0, 0, 0, 43, 241, 43, 43, 241, 0, 241, 241], [65, 86, 138, 86, 0, 0, 241, 43, 43, 107], [35, 0, 0, 90, 0, 0], [87, 237, 59, 0, 89, 0], [0, 0, 110, 0, 0, 35, 0, 51, 65, 0, 0, 0, 0, 124, 124], [78, 89, 0, 0, 91, 0, 0, 52, 0, 0, 0, 239, 0, 0, 239], [235, 235, 152, 0, 0, 0, 0, 107, 90, 0, 235], [87, 245, 0], [0, 111, 0, 0, 138, 0, 0, 138], [83, 0, 0, 140, 102, 225, 0, 140], [0, 0, 51, 0, 133, 0, 0, 0, 51, 0, 111, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 89, 0, 0, 0, 246, 51, 220, 0, 0], [0, 0, 45, 45, 0, 96], [140, 40, 0, 90, 248, 115, 0, 40, 0, 228, 228, 0, 228, 120, 0, 120, 111], [83, 140, 0, 0, 105, 226, 35, 51, 102, 226, 0, 220, 0, 131, 226, 226], [40, 0, 130, 105, 96, 89, 0, 89, 96, 0, 131, 0, 131, 131, 226], [], [0, 0, 0, 0, 51, 220, 0, 0, 35, 0, 110, 0, 0, 45, 244]], 'g0pD': [[0, 0, 45, 0, 238, 238, 40, 0, 0, 0, 0, 218, 0, 0, 0, 0, 126, 0, 45, 45], [0, 0, 0, 40, 0, 99, 248, 51, 0, 0, 0, 0], [0, 0, 45, 45, 86, 86, 0, 0, 0, 241, 43, 43, 107, 0, 0, 0, 0, 241, 43, 241, 241, 0, 43, 43], [35, 0, 244, 0, 0], [87, 237, 0, 105, 0, 237, 0], [0, 97, 0, 0, 0, 0, 132, 138, 0, 0, 138, 83, 51, 0, 232, 140, 51, 140, 0, 140, 140], [0, 111, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 89, 0, 0, 0, 0, 51, 0, 0, 0, 0, 0, 51], [108, 0, 0, 0, 140, 0, 140, 140], [0, 0, 89, 0, 0, 35, 65, 65, 0, 0, 0, 0, 124, 124], [124, 89, 131, 0, 120, 0, 0, 0, 0, 0, 239, 0, 0, 239], [0, 0, 0, 107, 235, 0, 235, 235, 152]], 'orig': [[0, 45, 45, 0, 0, 0, 45, 0, 0, 0, 45, 0, 238, 238, 40, 0, 0, 0, 0, 218, 0, 40, 0, 99, 90, 0, 0, 0, 248, 51], [0, 0, 0, 0, 43, 241, 43, 43, 241, 0, 241, 241], [65, 86, 110, 86, 0, 0, 241, 43, 43, 107], [35, 0, 90, 0, 0], [0, 237, 237, 0, 237, 0], [0, 0, 89, 0, 0, 35, 65, 65, 0, 0, 0, 0, 124, 124], [124, 89, 131, 0, 120, 0, 0, 0, 0, 0, 0, 239, 0, 0, 239], [0, 0, 0, 122, 0, 235, 0, 235, 235, 152, 87, 0, 0, 245], [0, 111, 0, 0, 138, 0, 0, 138], [83, 51, 0, 140, 51, 140, 0, 140, 140], [0, 0, 51, 0, 133, 0, 0, 0, 51, 0, 111, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 89, 0, 0, 0, 246, 51, 220, 0, 0], [0, 0, 45, 45, 0, 0, 87], [248, 40, 0, 248, 90, 115, 0, 0, 228, 228, 0, 228, 120, 0, 120, 111], [83, 140, 234, 105, 226, 35, 51, 102, 226, 226, 220, 0, 131, 226, 226], [40, 0, 130, 105, 96, 89, 0, 89, 96, 0, 131, 0, 131, 131, 226], [], [0, 0, 0, 0, 0, 51, 220, 0, 0, 35, 0, 110, 0, 0, 0, 45, 244]], 'g3pC': [[68, 0, 0, 45, 45, 0, 43, 43, 94, 29, 34, 0, 248, 0, 126, 40], [0, 0, 0, 0, 89, 225], [0, 70, 34, 0, 35, 0, 34, 0, 0, 92, 68, 0, 120, 110, 0, 58, 0, 61, 61, 133], [0, 0, 61, 61, 133, 96, 0, 45], [126, 0, 0, 0, 0, 99, 226], [83, 0, 40, 0, 56, 0, 0, 131, 0, 108, 126, 0, 0, 225, 151, 0, 110, 0], [0, 61, 0, 92, 68]], 'g2pB': [[0, 45, 45, 0, 0, 0, 45, 0, 238, 238, 40, 0, 40, 0, 99], [230, 110, 0, 0, 45, 45, 0, 0, 43, 0, 241, 0, 43], [34, 230, 126, 0, 0, 45, 94, 0, 241, 0, 0, 0, 126, 0, 241, 0, 40], [0, 114, 0, 45, 94, 118, 35, 0, 0, 0], [0, 0, 237, 0, 0, 0], [0, 0, 0, 131, 0, 0, 106, 0, 89, 230, 0, 0, 0, 45, 94, 0, 0, 107, 99, 0, 235, 235, 152], [0, 138, 0, 229, 0, 94, 0, 111, 0, 0, 0, 0], [0, 0, 94, 140, 102, 140, 0, 140, 140], [0, 0, 0, 112, 51, 0, 0, 89, 229, 0, 111, 0, 51, 0, 0, 0, 0, 51], [107, 91, 0, 45, 0, 94, 0, 0, 118, 0, 0, 68, 0, 0, 0, 0, 0, 0, 0, 0, 51, 0, 110, 140, 234, 0, 0, 0, 40, 0, 228, 228, 65, 133, 0, 99, 248, 90, 0, 70, 40, 0, 0, 0, 0, 230, 0, 131, 0, 0, 89]], 'g0pA': [[0, 0, 45, 45, 0, 52, 0, 0, 45, 0, 0, 0, 45, 0, 0, 224, 238, 40, 0, 90, 0, 0, 0, 0, 218, 0, 40, 0, 99], [0, 0, 0, 0, 43, 43, 0, 86, 86, 0, 0, 0, 241, 43, 43, 107], [35, 0, 90, 0, 0, 0, 0, 237, 237, 0, 237, 0], [0, 0, 110, 0, 0, 35, 68, 65, 65, 0, 0, 0, 0, 124, 124], [78, 89, 131, 0, 91, 0, 0, 0, 0, 0, 0, 239, 0, 0, 239], [0, 0, 0, 122, 0, 0, 0, 52, 235, 235, 152], [0, 111, 0, 0, 138, 0, 0, 138, 96, 87, 51, 0, 140, 51, 140, 0, 140, 140], [0, 0, 51, 0, 133, 0, 0, 0, 51, 0, 111, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 89, 0, 0, 0, 0, 0, 246, 51, 220, 0, 0], [0, 0, 45, 45, 0, 124], [248, 40, 0, 90, 115, 0, 0, 228, 228, 0], [83, 140, 234, 226, 35, 51, 0, 226, 0, 51, 226, 220, 0, 131, 226, 226], [40, 0, 130, 105, 96, 89, 0, 89, 0, 56, 0, 131, 0, 131, 131, 226], [0, 0, 0, 0, 0, 51, 220, 0, 0, 35, 0, 110, 0, 0, 0, 45, 244]], 'g4pC': [[0, 0, 45, 45, 0, 0, 40, 0, 0, 90, 0, 0, 51, 0, 244, 118, 0, 0, 224, 0, 35, 0, 0, 0, 64, 102, 78], [0, 0, 0, 92, 108, 0, 87, 0, 0, 133], [], [247, 29, 112, 51, 0, 0, 119, 0, 40], [], [124, 91, 90, 0, 0, 0, 105], [0, 0], [], [0, 0, 35, 0, 0, 0, 0, 0, 102], [], [68, 0, 43, 124, 91, 126, 124, 0, 124, 51], [], [0, 0, 112, 51], [236, 112, 61, 0, 0, 0, 102, 0, 112, 61, 0, 0, 0, 35]], 'g4pE': [[0, 111, 0, 0, 138, 0, 0, 138], [83, 51, 0, 140, 51, 140, 0, 140, 140], [0, 0, 51, 0, 133, 0, 0, 0, 51, 0, 111, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 89, 35, 0, 90, 0, 0], [0, 237, 0, 237, 51], [0, 0, 89, 0, 0, 35, 65, 65, 0, 0, 0, 0, 124, 124], [241, 241, 0, 40, 0, 225, 83, 0, 0, 68, 68, 0, 87, 0, 35, 138, 17, 0, 83, 0, 0, 91, 61, 0, 35, 0, 0, 0, 61, 35, 0, 0, 0, 35, 0, 90, 0, 0, 149, 0, 0, 0, 0, 40], [0, 0, 96, 0, 0, 45, 45], [94, 0, 0, 0, 0, 0, 45, 45, 152, 0, 45, 45], [230, 0, 0, 45, 45, 0, 0, 45, 45, 0, 0, 0, 0, 0, 40, 0], [0, 0, 0, 0, 45, 45, 0, 230, 0, 0, 45, 45, 56, 56, 0, 0, 138, 61, 51], [0, 0, 0, 230, 0, 0, 45, 45, 0, 0, 56, 0, 0, 0, 116, 0, 0, 40, 0, 0]], 'g2pC': [[0, 0, 0, 45, 45, 40, 120, 0, 97, 0, 0, 51, 43, 43, 133, 0, 40, 0, 0, 0, 149, 94, 51, 0, 0, 116, 0, 0], [0, 0, 45, 45, 0, 0, 0, 43, 43, 0, 92, 116, 130, 40, 0, 0, 0, 0, 0, 116, 130, 40, 0, 0, 83, 35], [0, 118, 0, 40, 0, 35, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 35, 0, 0, 0, 0, 0], [248, 0, 0, 0, 90, 0, 40, 0, 0, 0, 45, 45, 0, 108, 0, 35, 226, 0, 35, 0, 0, 0, 35, 0, 0, 0, 0, 0, 35, 0], [0, 35, 0, 0, 0, 0, 35, 0, 0, 68, 0, 228, 118, 0, 0, 0, 61, 0, 0, 61, 61, 0, 35, 0, 0, 0, 35, 0], [0, 114, 0, 68, 0, 232, 0, 120, 0, 0, 35, 0, 0, 0, 35, 0, 0, 0, 0, 0, 35, 0, 0, 0, 0, 0, 35, 0], [0, 245, 0, 151, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [35, 0, 61, 228, 0, 107, 0, 0, 0, 35, 0, 0, 35]], 'g4pB': [[0, 0, 45, 45, 0, 0, 0, 45, 0, 0, 0, 45, 0, 238, 238, 40, 0, 0, 0, 0, 218, 0, 40, 0, 99, 90, 0, 248, 51], [0, 0, 0, 0, 43, 241, 43, 43, 241, 0, 241, 241], [0, 86, 0, 0, 0, 86, 96, 0, 0, 241, 43, 43, 107], [35, 0, 90, 0, 0], [0, 0, 87, 237, 237, 0, 237, 0], [0, 0, 0, 35, 65, 65, 0, 0, 0, 0, 56, 110, 0, 124], [0, 89, 229, 0, 120, 0, 0, 0, 0, 0, 0, 239, 0, 0], [0, 0, 0, 107, 118, 235, 0, 235, 235, 152], [0, 111, 0, 0, 0, 0, 0, 138], [83, 51, 0, 140, 140, 51, 0, 140, 140], [83, 0, 51, 0, 0, 0, 0, 51, 0, 111, 0, 0, 0, 0, 110, 0, 0, 0, 0, 51, 0, 0, 89], [0, 0, 0, 107, 0, 0, 0, 61, 61, 0, 40, 110, 0, 0, 61, 0, 0, 110, 65, 0, 0, 35, 0, 35, 0, 0, 234, 0, 226, 0, 0, 0, 0, 0, 0, 0, 35, 86, 0, 0, 35]], 'g1pD': [[111, 43, 43, 0, 35, 0, 119, 0, 0, 90, 0, 0, 126, 0, 45, 0, 244, 0, 52, 0, 0, 45, 45], [43, 43, 248, 0, 0, 90, 0, 40, 0, 0, 0, 0, 45, 0, 0, 68, 0, 0, 0, 0, 35, 40, 0, 58, 152, 40], [0, 70, 40, 0, 0, 0, 40, 0, 152, 35, 35, 228, 0, 152, 0, 51, 0, 152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 70, 40, 0, 107, 0, 81, 0, 0, 0, 45, 45, 0, 0, 61, 0, 0, 61, 61, 0, 70, 40, 0, 65, 61, 0]], 'g4pD': [[0, 0, 45, 45, 0, 40, 0, 0, 0, 43, 0, 0, 0, 0, 90, 0, 40], [0, 0, 152, 0, 0, 0, 0, 0, 45, 81], [51, 0, 118, 0, 51, 0, 0, 241, 0, 0, 0, 0, 238], [0, 152, 230, 0, 126, 220, 0, 0, 228, 118], [0, 228, 0, 43, 0, 136, 43, 43, 107], [0, 138, 0], [0, 0, 150, 0, 0, 78, 111, 0, 35, 0, 0, 56, 0, 35, 78], [0, 87, 0, 0, 0, 0, 110, 87, 102, 0, 110, 0, 35, 110, 152], [0, 0, 0, 94, 64, 0, 0, 0, 102, 110, 0, 56, 107, 126], [0, 124, 0, 110, 91, 116, 78, 0, 0, 89, 0, 35], [0, 0, 0, 89, 0, 35, 0, 0, 0, 0, 0, 0, 152, 0, 0, 35], [0, 29, 51, 0, 248, 40], [0, 110, 0, 0, 51, 0, 110, 0, 96, 0, 151], [0, 124, 0, 110, 0, 0, 0, 102, 0, 110, 0, 68, 96, 0, 51, 0, 220], [0, 124, 0, 97, 0, 105, 0, 0, 124], [0, 0, 0, 107, 0]], 'g2pE': [[43, 114, 0, 0, 0, 0, 0, 40, 0, 43, 111, 40, 0, 0, 73, 40, 0, 90, 0, 0, 0, 0, 0, 221, 221, 34], [114, 0, 0, 0, 0, 0, 102, 0, 43, 0, 43, 151, 245, 0], [0, 0, 0, 0, 0, 0, 51, 92, 43, 35, 43, 43, 43, 0, 238, 43, 96, 0, 0, 0, 65, 0, 17, 0], [43, 43, 248, 0, 0, 0, 94, 0, 0, 52, 43], [78, 0, 114, 110, 114, 248, 0, 152, 0, 0, 34, 40]], 'g3pA': [[0, 45, 45, 0, 0, 0, 45, 0, 0, 0, 0, 0, 0, 0, 0, 45, 0, 238, 0, 0, 0, 0, 0, 238, 40, 0, 40, 0, 99, 0, 0, 248, 51], [0, 0, 0, 0, 43, 43, 0, 241, 241, 0, 241, 241, 0, 86, 86, 0, 0, 0, 241, 43, 43, 107], [35, 0, 90, 0, 0, 0, 0, 237, 0, 237, 0], [0, 0, 89, 0, 0, 35, 0, 65, 0, 0, 124, 124, 0, 0, 0], [78, 89, 131, 0, 120, 0, 0, 0, 239, 0, 0, 239, 0, 0, 0, 122, 0, 235, 0, 235, 235, 152], [0, 97, 0, 0, 0, 132, 138, 0, 0, 138], [83, 51, 0, 140, 51, 140, 0, 52, 223, 140, 140], [0, 0, 51, 0, 133, 0, 0, 51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 246, 51, 0, 0], [241, 0, 40, 0, 225, 83, 0, 0, 68, 0, 126, 0, 87, 0, 35, 138, 17, 0, 83, 0, 0, 91, 61, 0, 35, 0, 0, 0, 61, 35, 0, 0, 0, 35, 0, 90, 0, 0, 0, 0, 0, 40], [87, 0, 0, 0, 107, 0, 61, 0, 0, 61, 61, 0, 40, 110, 0, 0, 61], [124, 65, 0, 0, 61, 0, 0, 35, 0, 35, 0, 0, 0, 108, 234, 0, 226, 0, 0, 0, 35, 0, 56, 0, 0, 35, 99, 107], [107, 0, 0, 45, 45, 0], [248, 40, 0, 248, 90, 133, 0, 78, 228, 228, 0, 228, 120, 0, 120, 111, 83, 140, 234, 226, 105, 0, 35, 51, 102, 226, 226, 220, 0, 131, 226, 226, 130, 105, 40, 96, 89, 0, 89, 96, 0, 131, 0, 131, 131, 226, 0, 0, 0, 0, 0, 51, 220, 0, 0, 35, 0, 56, 90, 0, 0, 0, 45, 45]], 'g1pB': [[0, 0, 45, 0, 238, 238, 40, 0, 0, 0, 40, 0, 99, 0, 52, 0, 0, 45, 45], [0, 0, 0, 0, 43, 241, 241, 241, 241, 0, 43, 43], [0, 86, 86, 0, 0, 0, 241, 43, 43, 107], [64, 35, 0, 90, 0, 0, 0, 237, 237, 0, 237, 0], [0, 0, 89, 0, 0, 35, 0, 65, 0, 0, 0, 0, 124, 124], [34, 131, 0, 120, 0, 0, 0, 239, 0, 0, 239], [0, 107, 118, 0, 235, 235, 152], [0, 0, 138, 0, 111, 0, 0], [140, 51, 140, 0, 140, 140, 0, 0, 0, 51], [0, 111, 0, 0, 0, 0, 51, 0, 0, 0, 51, 0, 0, 246, 0, 0, 51, 118, 0, 110], [0, 68, 0, 87, 0, 0, 35, 138, 17, 0, 241, 241, 0, 40, 0, 225, 83, 0, 0, 92, 0, 83, 0, 0, 91, 61, 40, 112, 111, 0, 35, 0, 0, 61, 35, 0, 0, 40, 0, 112, 0, 0, 0, 118], [0, 0, 0, 0, 45, 45, 0, 244], [133, 0, 228, 228, 0, 248, 40, 0, 248, 90], [131, 226, 226, 64, 0, 0, 83, 140, 92, 56, 105, 226, 35, 51], [131, 131, 226, 0, 0, 64, 40, 130, 105, 96, 0, 89, 0, 89], [0, 45, 244, 126, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 0, 35]]}\n"
     ]
    }
   ],
   "source": [
    "vector_dict = {}\n",
    "for key, value in question_mapping.items():\n",
    "    vector_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        vector_dict[key][student] = []\n",
    "        for sent in answer:\n",
    "            words = sent.split(' ')\n",
    "            temp_list = []\n",
    "            for w in words:\n",
    "                for cluster_key, cluster_value in clust_dict.items():\n",
    "                    if w in clust_dict[cluster_key]:\n",
    "                        temp_list.append( cluster_key)\n",
    "            vector_dict[key][student].append(temp_list)\n",
    "            \n",
    "for k, v in vector_dict.items():\n",
    "    print(k, '    ', v)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_name = {}\n",
    "rep = 0\n",
    "for key, value in vector_dict.items():\n",
    "    for student, vector in value.items():\n",
    "        for v in vector:\n",
    "            vector_name[tuple(v)] = rep\n",
    "            rep+=1\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskc      {'g0pC': [0, 1, 2, 3, 4, 5, 6, 7, 8], 'g0pE': [9], 'g1pA': [10, 11, 12, 76, 14, 15, 16, 17, 18, 19, 20], 'g3pB': [21, 22, 23, 24, 25, 26, 27, 28, 29], 'g0pB': [30, 74, 153, 108, 137, 78, 133, 134, 82, 39, 40, 138, 42], 'g2pA': [43, 153, 45, 46, 47, 48, 49, 50, 51, 133, 53, 82, 55, 56, 57, 86, 909, 60], 'g0pD': [61, 62, 63, 64, 65, 66, 67, 68, 137, 70, 71], 'orig': [72, 153, 74, 155, 76, 137, 78, 79, 133, 134, 82, 83, 84, 85, 86, 909, 118], 'g3pC': [89, 90, 91, 92, 93, 94, 95], 'g2pB': [96, 97, 98, 99, 100, 101, 102, 103, 104, 105], 'g0pA': [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118], 'g4pC': [119, 120, 909, 122, 909, 124, 750, 909, 127, 909, 129, 909, 131, 132], 'g4pE': [133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143], 'g2pC': [144, 145, 146, 147, 148, 149, 150, 151], 'g4pB': [152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163], 'g1pD': [164, 165, 166, 167], 'g4pD': [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'g2pE': [184, 185, 186, 187, 188], 'g3pA': [189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'g1pB': [202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217]}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "pro_dict = {}\n",
    "for key, value in vector_dict.items():\n",
    "    pro_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        pro_dict[key][student] = []\n",
    "        for v in answer:\n",
    "            ans = tuple(v)\n",
    "            pro_dict[key][student].append(vector_name[ans])\n",
    "\n",
    "for key, value in pro_dict.items():\n",
    "    print(key, '    ', value)\n",
    "    break\n",
    "    \n",
    "print(len(pro_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyfpgrowth\n",
    "inp = [\"taske\", \"taska\", \"taskb\", \"taskc\", \"taskd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_growth(transactions):\n",
    "    patterns = pyfpgrowth.find_frequent_patterns(transactions, 3)\n",
    "    frequent_list = []\n",
    "    for p in patterns:\n",
    "        if len(p) < 3:\n",
    "            continue\n",
    "        else:\n",
    "            frequent_list.append(list(p))\n",
    "    return frequent_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_sub(sub, lst):\n",
    "    ln = len(sub)\n",
    "    for i in range(len(lst) - ln + 1):\n",
    "        if all(sub[j] == lst[i+j] for j in range(ln)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(frequent_list):\n",
    "    output_dict= {}\n",
    "    for lst in frequent_list:\n",
    "        for k, v in pro_dict.items():\n",
    "            for name, vec in v.items():\n",
    "                if is_sub(lst,vec):\n",
    "                    if k not in output_dict:\n",
    "                        output_dict[k] = [name]\n",
    "                    else:\n",
    "                        output_dict[k].append(name)\n",
    "    return output_dict\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'taske': {'orig', 'g0pE', 'g2pB', 'g1pB'}, 'taska': {'g0pE', 'g3pC', 'g2pC', 'g4pC', 'orig'}, 'taskd': {'g2pA', 'g4pC', 'g3pA'}}\n"
     ]
    }
   ],
   "source": [
    "final= {}\n",
    "for task in inp:\n",
    "    transactions = []\n",
    "    for k, v in pro_dict.items():\n",
    "        if k == task:\n",
    "            for name, vec in v.items():\n",
    "                transactions.append(vec)\n",
    "            frequent_list = fp_growth(transactions)\n",
    "    output_dict = output(frequent_list)\n",
    "    for key, value in output_dict.items():\n",
    "        final[key] = set(value)\n",
    "        \n",
    "# print(transactions)\n",
    "\n",
    "print(final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xl = pd.ExcelFile(\"corpus_final.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = xl.parse(\"File list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = df[['File','Category']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is :  0.9\n",
      "Recall is :  0.5934065934065934\n",
      "Accuracy is :  0.6359649122807017\n",
      "F1 Score is :  0.7152317880794702\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "fp = 0\n",
    "for key, value in final.items():\n",
    "    for v in value:\n",
    "        ans = v+key+'.txt'\n",
    "        head = key\n",
    "        for index, row in c.iterrows():\n",
    "            if row['File'].split('_')[1].split('.')[0] == head:\n",
    "                if row['File'].split('_')[0] == v:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        tp+=1\n",
    "                    else:\n",
    "                        fp+=1\n",
    "                else:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        fn +=1\n",
    "                    else:\n",
    "                        tn+=1\n",
    "\n",
    "precision = float(tp/(tp+fp))                        \n",
    "print('Precision is : ', precision)\n",
    "recall = float(tp/(tp+fn))\n",
    "print('Recall is : ', recall)\n",
    "print('Accuracy is : ', (tp+tn)/(tp+fn+tn+fp))\n",
    "print('F1 Score is : ', 2*precision*recall/(precision+recall))\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
